## 内存相关: `单机4-6G`

0. redis 中一个字母就占用一个 byte: Redis 是 C 语言开发的, char 占用一个 字节
1. 配置中 maxmemory 配置最大使用内存, 内存超出则会淘汰之前的数据, 如果无法淘汰则会报错

   - ~~也可以配置当 Redis 内存超出物理内存限制时, 内存的数据会开始和磁盘产生频繁的交换 (swap)~~
   - 内存满了会触发缓存淘汰, 之后内存还是不够就会报错
   - 不配置默认(0) 64 位机器默认使用最大内存+ 32bit 隐式 3G: 单位是字节 byte
   - 查看: info memory / config maxmemory / 配置文件

2. 过期策略: `redis 使用了 惰性删除 和 定期删除(Redis 每秒 10 次)`

   - [省内存耗性能]定时删除: 数据过期后马上就被删除, CPU 要时刻计算着过期的 key 压力过大
   - [耗内存省性能]惰性删除(阻塞): 数据过期不处理, 等到下次使用的时候判断是否过期, 会导致有很多不被访问的 Key
   - 定期删除: 是对上两种的折中, 每 1s 时间执行 10 次删除, 限制删除操作的时长和频率减少删除操作对 CPU 的影响

     - 周期性轮询, 随机抽取[一部分 key]{20 个}, 删除其中过期的 key, 如果过期占比大于 25%, 则继续抽样过期(利用占比控制删除频率)
     - **检测频率时长可以自定义**, 内存压力也不大
     - 还是可能导致一些 key 到期不会被删除
     - 使用前还是需要看是否过期[惰性检查]

     ![avatar](/static/image/db/redis-memory-job.png)

3. Redis 是使用了 惰性删除 + 定期删除

   - key 过期信息是用 Unix 绝对时间戳表示的: 这里就会涉及主从同步机器的时钟问题(可能导致两台机器同一个 key 的过期时间不一样)
   - 定期删除: 定期扫描只会扫描设置了过期时间的键, 设置过期时间的 Key Redis 会单独存储
   - volatile 表示设置过期时间的 key
   - redis 会记录对象最后一次被应用程序访问的时间, 一个 key 到期了并不是马上就被删除
   - 数据太多, 定时删除无法删除完全([有可能]每次删除完过期的 key 还是超过 25%), 也不会被访问了: 这些 key 的删除走的是内存淘汰策略

4. 缓存淘汰策略: 8

   - noeviction: 不在提供写服务, 只提供读删除操作; 满了之后会 set 操作会 OOM
   - volatile-lru: 针对设置了过期时间的 key least recent used
   - allkeys-lru: 针对所有 key
   - volatile-lfu
   - allkeys-lfu
   - volatile-random: 随机淘汰带有过期时间的 key
   - allkeys-random: 是随机的淘汰 key
   - volatile-ttl: Remove the key with the nearest expire time (minor TTL)
   - _noeviction 之外策略会删除 key 释放空间, 如果释放的空间不足则报错_

   ```C
   typedef struct redisObject {
     unsigned type:4;//对象类型（4位=0.5字节）
     unsigned encoding:4;//编码（4位=0.5字节）
     unsigned lru:LRU_BITS;//记录对象最后一次被应用程序访问的时间（24位=3字节）
     int refcount;//引用计数。等于0时表示可以被垃圾回收（32位=4字节）
     void *ptr;//指向底层实际的数据存储结构, 如：SDS等(8字节)
   } robj;
   ```

5. Redis 的 LRU: 一种常用的页面置换算法[hash + 双向链表]

   - redis 的 LRU 算法并不是真实的 LRU 算法
     - **通过抽样的方式进行删除: Redis 随机取出若干 key 在进行最近最少使用**
     - LRU 需要额外的空间进行存储[pre/next]: LRU=DLinkedList + HashMap
     - 可能存在某些 key 值使用很频繁, 但是最近没被使用, 从而被 LRU 算法删除
   - maxmemory-samples: 5
     - 3 最快, 内存少, 但是准确性太差
     - 5 平衡的好
     - 10 接近 LRU 但是耗内存
   - LRU 实现的数据类型的选择

     - DLinkedList: 新来的放入 head 单链表也可以, 但是淘汰最后一个单链表就需要遍历[因此需要使用 DlinkedList]
     - HashMap: 保存和查找都是 hash O(1)
     - 实现思路:
       1. save(key, value): 在 HashMap 找到 Key 对应的节点
          - 如果节点存在, 更新节点的值, 并把这个节点移动队头
          - 如果不存在, 需要构造新的节点, 并且尝试把节点塞到队头
          - 如果 LRU 空间不足, 则通过 tail 淘汰掉队尾的节点, 同时在 HashMap 中移除 Key
       2. get(key): 通过 HashMap 找到 LRU 链表节点
          - 因为根据 LRU 原理, 这个节点是最新访问的, 所以要把节点插入到队头, 然后返回缓存的值

   - Redis LRU
     1. 由于 LRU 算法需要用链表管理所有的数据, 会造成大量额外的空间消耗 + 频繁的移动节点: redis 采用的是近似算法
     2. Redis 通过对少量的 key 采样, 并淘汰采样的数据中最久没被访问过的 key
     3. Redis 可以配置样本数量来调整算法的精度: 使其近似接近真实的 LRU 算法, 同时又避免了内存的消耗
     4. 记录对象最后一次被应用程序访问的时间: lru:LRU_BITS[24 位只能存储 194 天]
     5. 但是 redis 并不是比较 lru 和当前时间, 而是维护了一个全局属性 lru_clock[定时更新 100ms], 最终比较的是 lru_clock 和 lru, 节约了每次获取当前系统时间
   - redis lru flow
     1. Redis 在淘汰数据时, 第一次随机选出 N 个数据放到候选集合, 将 lru 字段值最小的数据淘汰
     2. 当再次需要淘汰数据时, 会重新挑选数据放入第一次创建的候选集合: [挑选标准]进入该集合的数据的 lru 的值必须小于候选集合中最小的 lru 值
     3. 如果新数据进入候选集合的个数达到了 maxmemory-samples 设定的值, 那就把候选集合中 lru 最小的数据淘汰

6. Redis 的 LFU: lru 的高 16 位记录访问时间, 低 8 位[0-255]记录访问频率

   - Redis 使用的是一种基于概率的对数器来实现 counter 的递增
   - r 给定一个旧的访问频次, 当一个键被访问时, counter 按以下方式递增：

     - 提取 0 和 1 之间的随机数 R。
     - counter - 初始值（默认为 5）, 得到一个基础差值 baseval, 如果这个差值小于 0, 则直接取 0
     - 概率 P 计算公式为：`1/(baseval * lfu_log_factor + 1)`: lfu_log_factor 对数因子[10]
     - 如果 R < P 时, 频次进行递增（counter++）
     - `random(0, 1) < 1 /((old_counter - 5)*lfu_log_factor + 1) ? counter++ : counter`

     ![avatar](/static/image/db/redis-flu.png)

   - 默认访问 1m 才会到最大值
   - counter 一直会增加, 所以不能反映热度, 需要一段时间不访问了就降下来
   - counter 的减少速度由参数 `lfu-decay-time[1]` 进行控制: N 分钟内没有访问, counter 就要减 N
     - 取出当前的时间戳和对象中的 lru 属性进行对比
     - 计算出当前多久没有被访问到: 比如计算得到的结果是 100 分钟没有被访问
     - 然后再去除配置参数 lfu_decay_time, 如果这个配置默认为 1 也即是 100/1=100, 代表 100 分钟没访问: 所以 counter 就减少 100。

### 查看

![avatar](/static/image/db/redis-memory-info.png)

1. info memory

   |         属性名          |                           属性说明                            |
   | :---------------------: | :-----------------------------------------------------------: |
   |       used_memory       | Redis 分配器分配的内存总量, 指 Redis 存储的所有数据所占的内存 |
   |    used_memory_human    |                 以可读的形式返回 user_memory                  |
   |     used_memory_rss     |                 Redis 进程占用的物理内存总量                  |
   |    used_memory_peak     |                    used_memory 使用的峰值                     |
   | used_memory_peak_human  |                  可读格式返回 usedmemorypeak                  |
   |     used_memory_lua     |                    Lua 引擎消耗的内存大小                     |
   | mem_fragmentation_ratio |          usedmemoryrss/used_memory 比值, 内存碎片率           |
   |      mem_allocator      |            Redis 所使用的内存分配器, 默认 jemalloc            |

2. 内存: 对象内存 + 缓冲内存 + 自身内存 + 内存碎片
3. 对象内存

   - 占用最大的一块, 存储着所有的用户数据
   - key 对象是字符串
   - value 对象: String、Hash、List、Set、Zset, 每种数据类型在使用的时候占用的内存不同

4. 缓冲内存: 客户端缓冲、AOF 缓冲区、复制积压缓冲区

   - 客户端缓冲: 普通的客户端连接
   - AOF 缓冲区: AOF 在写入文件之前会先写入到缓冲区, 然后根据不同的持久化策略向磁盘进行同步 + AOF 重写时也有一个 AOF 重写缓冲区 + 一般 AOF 缓冲区都会比较小
   - 复制积压缓冲区: 主要用于主从同步. 在进行主从同步时, Redis 会将最新的命令写入到复制积压缓冲区, 在进行复制的时候, 会校验复制偏移量是否在复制积压缓冲区中, 如果是则进行部分复制, 否则进行全量复制. 它默认情况下是 1MB, 我们需要根据实际请求适当调整他的大小, 毕竟设置太小的话, 可能会使部分复制退化为全量复制

5. 自身内存

   - 自身内存主要指 AOF/RDB 的时候 Redis 创建子进程内存的消耗, 一般这部分的消耗会比较小

6. 内存碎片

   - 目前可选的分配器有 jemalloc、glibc、tcmalloc, 默认 jemalloc
   - **出现高内存碎片问题的情况**: 大量的更新操作, 比如 append、setrange; 大量的过期键删除, 释放的空间无法得到有效利用
   - 解决办法: 数据对齐, 安全重启[高可用/主从切换]

---

## reference

1. [redis-lru/lfu](https://blog.csdn.net/zwx900102/article/details/113806440)
