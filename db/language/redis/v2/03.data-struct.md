## 数据类型 & 基本指令

- overview
  ![avatar](/static/image/db/redis-data-type.png)
- struct-detail
  ![avatar](/static/image/db/redis-data-detail.png)
- string
  ![avatar](/static/image/db/redis-string-int.png)
- rehash & hash
  ![avatar](/static/image/db/redis-data-hash.png)
- ziplist: 使用连续的内存的使用[cache line/L1], 并非真正的压缩
  ![avatar](/static/image/db/redia-data-ziplist.png)
  - 所有的操作都是通过指针与解码出来的偏移量进行的
  - 当一个列表只有少量数据的时候, 并且每个列表项要么就是小整数值, 要么就是长度比较短的字符串, 那么 Redis 就会使用压缩列表来做列表键的底层实现
- linkedlist
  ![avatar](/static/image/db/redis-data-linkedlist.png)
- intset: 不重复的中枢集合
  ![avatar](/static/image/db/redis-data-intset.png)
  - 当一个集合只包含整数值元素, 并且这个集合的元素数量不多时
- skiplist
  ![image](https://user-images.githubusercontent.com/42330329/169278122-5ec2feb6-1b4b-4e1a-81d0-b81157f59e8d.png)
  ![avatar](/static/image/db/redis-struct-skiplist.png)
- quicklist
  ![avatar](/static/image/db/redis-struct-quicklist.png)
  - 是 ziplist 和 linkedlist 的混合体
  - 将 linkedlist 按段切分, 每一段使用 ziplist 来紧凑存储, 多个 ziplist 之间使用双向指针串接起来

1. 查看类型相关的命令
   ```shell
   set age 12
   set name zack
   type age # string
   type name # string
   object encoding age # int
   object encoding name # embStr
   ```
2. key 命令在数据很多时不建议使用: 消耗资源
   - 使用 scan 替代: cursor + key 的正则模式 + 遍历的 limit hint

### string

1. 二进制安全

   - 二进制安全: redis server 与客户端交互式使用的是字节流[一字符对应一字节], 而不是字符流[各个语言间的对数字宽度的理解可能不一样: 数字上可能出现溢出];
   - 字节流: 只要使用的客户端具有一致的编解码, 数据就不会被破坏
   - c 语言里面 `\0` 表示结束, 如果**字符串**里包含则会出现之后字符丢失的问题; sds 是根绝 len 读取的
   - **redis 没有数据类型的概念: 客户端存 2L, 但是 redis 返回的就是 2 字节, 此时就需要客户端自己判断类型做转换了**

2. string -- int
3. string -- sds

   - raw/embstr

     - 字符串是一个字符串值并且长度大于 64 个字节就会使用 SDS 方式进行存储, 并且 encoding 设置为 raw
     - 若是「字符串长度小于等于 64 个字节」就会将 encoding 改为 embstr 来保存字符串

     ```c#
     // redis 3.2
     struct sdshdp {
        int len;  // 空间有浪费
        int free; // 空间有浪费
        char buf[];
     };

     // redis 3.2 later
     len and free is less for less memory and with flag to mark[1byte] type
     struct sdshdp {
        int8 len;
        int8 free;
        int8 flags;
        byte buf[];  // 这个大于等于45时, 为raw类型
     };
     ```

   - sds01: 获取字符串只要读取 len 的值就可, 时间复杂度变为 O(1)
   - sds02: 会先根据 len 属性判断空间是否满足要求, 若是空间不够, 就会进行相应的空间扩展, 所以「不会出现**缓冲区溢出**的情况」
   - sds03: 提供「**空间预分配**」和「**惰性空间释放**」两种策略, 减少连续的执行字符串增长带来内存重新分配的次数; 压缩也不会立即回收{free 记下来后面使用}
   - sds03 空间预分配: 当修改字符串后的长度 len 小于 1MB, 就会预分配和 len 一样长度的空间, 即 len=free; 若是 len 大于 1MB, free 分配的空间多分配 1m[need+1M]
   - sds04: SDS 是二进制安全的[c 字符串非二进制安全], 除了可以储存字符串以外还可以储存二进制文件{c 语言中的字符串是以空字符串作为结束符, 一些图片中含有结束符, 因此不是二进制安全的}; sds 最后会有 `\0` 为了兼容 c 的函数库

   |                c-string                 |               sds               |
   | :-------------------------------------: | :-----------------------------: |
   |       获取长度的时间复杂度为 O(n)       |   获取长度的时间复杂度为 O(1)   |
   | n 次增长字符串必然会带来 n 次的内存分配 | n 次增长字符串内存分配的次数<=n |
   |            不是二进制安全的             |         是二进制安全的          |
   |             只能保存字符串              |      还可以保存二进制数据       |
   |    数据溢出{导致其他字符串值被修改}     |    空间预分配 / 惰性空间释放    |

4. 字符串命令: 数值{点赞,预扣库存减少数据库} || string || bitmmap || redis 在使用时一定要统一客户端的编码

   ```js
   // CRUD + 长度
   get / mget || set / mset / setnxex || getset || del || strlen;
   // 追加/覆盖/部分获取
   append || setrang || getrange
   // 原子: 只能是整数[1.6 incr 会报错]
   incr / decr / incrby / decrby / ~~decrbyfloat~~
   // 一定返回
   type k1 string
   // k1 对应的 value 是 string 返回 embstr || raw{bitset 也是}
   // k1 对应的 value 是 int 返回 int: 因为可以做 incr 操作嘛
   // k1 对应的 value 是 float 返回 embstr
   object encoding k1            // key 上的 encoding 是为了优化, 如果是 int 则可以直接 incr 操作; 如果是 embstr 则会先判断能否转换为 int[能则incr, 不能则报错]
   ```

   ```js
   // 二进制安全
   set k1 99999                  // keylen 是 5, 不会存成4字节的整数
   set k1 中                     // keylen 是 2[gbk]/3[utf8], 具体和客户端传过来时的字符集相关: 客户端先变成字节数组在出去 server
   ```

   - bitmap: 登录{key 是用户}/活跃用户个数{key 是日期+bitop or}

     ```js
     // bitmap: 长度=offset/8 + 1
     setbit k1 0  1                 // 长度为 1
     setbit k1 7  1                 // 长度为 1
     setbit k1 8  1                 // 长度为 2
     setbit k1 30 1                 // 长度为 4

     // BITPOS key bitValue [start] [end] 返回数据表示 Bitmap 中第一个值为 bitValue 的 offset 位置
     // 从(0)*8 - (1+1)*8即0-15 的二进制位上找第一个出现 1 的位置(在整个k1中): 最后两个参数不是二进制位置
     bitpos k1 1 0  1               // 0
     // 2 ~ 3 ==> (2+1)*8 ~ (3+1)*8 ==> 24 ~ 32
     bitpos k1 1 2  3               // 30

     // BITOP <operation> destkey key [key ...]
     bitop and/OR/NOT/XOR k1 k2
     bitcount k1 1 0  1             // 3 {0-15二进制上的1的个数}
     ```

### bitmap

1. 使用场景: 大数据量下的二值状态统计[登录/签到/打卡/ip 黑名单/用户存在]
2. 底层数据结构用的是 string 类型的 SDS 数据结构来保存位数组

   - 把每个字节数组的 8 个 bit 位利用起来
   - 每个 bit 位 表示一个元素的二值状态: 不是 0 就是 1

3. Bitmap 看成是一个 bit 为单位的数组

   - 数组的每个单元只能存储 0 或者 1
   - 数组的下标在 Bitmap 中叫做 offset 偏移量

4. 使用举例

   ```shell
   # 1. 判断用户登陆态
      # 登陆
      SETBIT login_status 10086 1
      # 检查该用户是否登陆
      GETBIT login_status 10086
      # 登出
      SETBIT login_status 10086 0

   # 2. 用户每个月的签到情况: key 可以设计成 uid:sign:{userId}:{yyyyMM}
      # 用户在 2021 年 5 月 16 号签到
      SETBIT uid:sign:89757:202105 15 1
      # 判断编号 89757 用户在 2021 年 5 月 16 号是否打卡。
      GETBIT uid:sign:89757:202105 15
      # 编号 89757 用户在 2021 年 5 月签到次数
      BITCOUNT uid:sign:89757:202105
      # 这个月首次打卡时间
      BITPOS uid:sign:89757:202105 1
   ```

![avatar](/static/image/db/redis-struct-bitmap-usage.png)

### hash: k, map<k, v>

1. hash: ht / ziplist
   - hash 对象保存的所有键值对的键和值的字符串长度均小于 64 字节
   - 且 Hash 对象保存的键值对数量小于 512 个 则使用 ziplist
   - 否则使用 hashtable
2. hash 命令

   ```js
   // 添加
   hset/hmset/hsetnx
   HSET key k1 v1 // HGET key k1 [v1]
   // 查找
   hget/hmget/hgetall
   hscan key cursor [pattern] [count]
   // 原子
   hincrby/hincrbyfloat
   // 删除
   hdel
   // 长度
   hlen
   // 判断
   hexists key / hkeys / hvals;
   ```

### list: 存取有序

1. 3.2 之前是 ziplist / linkedlist; 之后是 quicklist{双向链表 + 压缩列表}
2. [配置文件中能改]列表对象中 `字符串长度 < 64 字节且元素个数 < 512` 使用 ziplist 编码, 则使用 linkedlist
3. list: [双端无环链表]链表的操作无论是头和尾效率都极高, 可以当做 stack 或者 queue 或者 数组[lset/lindex] 或 阻塞单播队列 使用

   ```js
   // 个数
   llen

   // 添加
   lpush/rpush
   // 删除
   lpop/rpop
   ltim k1 start stop // 只保留 [start, stop] 数据
   // 获取所有
   lrange key 0 -1

   // used as array
   lindex key 2
   // 修改第3+1个元素为 v1
   lset k1 3 v1
   // 删除count个v1: count 为负数这从后面开始删
   lrem k1 [-]count v1
   // 在 第一个 v1 后面插入一个 v2
   linsert k1 after/before v1 v2
   ```

4. 应用: 消息队列、最新列表
   - 列表频繁更新 + 分页获取使用: 这个可能导致元素重复取出或遗漏

### set

1. set: intset + hashtable
   - 个数小于 512 时使用 intset
2. set

   ```js
   // 添加
   sadd key v1 [v2 ...]
   // 删除
   srem key member [member ...]
   // 获取所有
   smembers key
   // 判断
   sismember key
   // 个数
   scard key

   // 随机找出: 不删除
   srandommember key COUNT
      // COUNT 正数: 取出一个去重的结果集{不能超过已有集}
      // COUNT 负数: 取出一个有重的结果集{一定满足 count 个数}
      // COUNT 0: 不返回
   // 随机找出: 删除
   spop key COUNT

   // [感兴趣]差集: 在k1中且不在k2中
   sdiff[store] k3 k1 k2
   // [共同好友]交集: k1与k2的交集放入 k3
   sinterstore  k3 k1 k2
   // 并级
   sunion key key
   ```

3. 数据量较大的情况下, 如果直接执行这些计算, 会导致 Redis 实例阻塞
   - **专门部署一个集群用于统计**, 让它专门负责聚合计算
   - 或者是把数据读取到客户端, 在客户端来完成聚合统计

### zset

1. skiplist/ziplist
   - 小于 128 个且每个小于 64 则使用 ziplist
2. zset

   ```js
   // 音乐热歌榜
   127.0.0.1:6379> zadd k1  8 apple 2 banana 3 orange             // (integer) 0
   127.0.0.1:6379> zrange k1 0 -1 withscores
      // 1) "banana"
      // 2) "2"
      // 3) "orange"
      // 4) "3"
      // 5) "apple"
      // 6) "8"
   127.0.0.1:6379> zrange k1 0 -1
      // 1) "banana"
      // 2) "orange"
      // 3) "apple"
   // 取分数是 3-8 之间的
   127.0.0.1:6379> ZRANGEBYSCORE k1 3 8
      // 1) "orange"
      // 2) "apple"
   // 取分数最低的两个
   127.0.0.1:6379> ZRANGE k1 0 1
      // 1) "banana"
      // 2) "orange"
   // 取分数最高的两个
   127.0.0.1:6379> ZrevRANGE k1 0 1
      // 1) "apple"
      // 2) "orange"
   // 查看分数
   127.0.0.1:6379> zscore k1 apple
      // "8"
   // 查看排名
   127.0.0.1:6379> zrevrank k1 apple
   (integer) 0

   // 集合操作: 权重/聚合
   127.0.0.1:6379> zadd k1 80 tom 60 sean 70 bady     // (integer) 3
   127.0.0.1:6379> zadd k2 60 tom 40 sean 70 zack     // (integer) 3
   127.0.0.1:6379> ZUNIONSTORE unkey 2 k1 k2          // (integer) 4
   127.0.0.1:6379> ZRANGE unkey 0 -1 withscores
      // 1) "bady"
      // 2) "70"
      // 3) "zack"
      // 4) "70"
      // 5) "sean"
      // 6) "100"
      // 7) "tom"
      // 8) "140"
   ```

3. 应用: 排行榜

### hyperloglog

#### introduce

1. HyperLogLog 是一种基数估算算法
   - 所谓基数估算: 就是估算在一批数据中, 不重复元素的个数有多少[基数 cardinality]
2. cardinality 集合 A 中不重复数的个数
   - [1,2,3,4,5] 基数是 5 [1,2,3,4,5,5] 基数仍然是 5
   - 可以理解为：distinct value
3. 如果我们用 hash 来存储并基数, 在数据量很大的时候, hash 占用的空间也会线性增长.
4. HLL 的能力便是能够以很小的空间占用预估很大数据集的基数.
   - 注意是预估 (estimation) 不是精确数
   - memory_size= log(log(list_size))
5. [不能知道是谁]使用场景: `大数据量下, 一个 key 关联了一个数据集合, 同时对这个数据集合做估值统计`
   - 日活/月活数
   - 页面的 UV/PV
   - 统计用户每天搜索不同词条的个数
   - 统计注册 IP 数
   - 数据库基数统计

#### 使用

1. sample

   ```shell
   redis> PFADD  databases  "Redis"  "MongoDB"  "MySQL"
   (integer) 1
   redis> PFCOUNT  databases
   (integer) 3
   redis> PFADD  databases  "Redis"         # Redis 已经存在, 不必对估计数量进行更新
   (integer) 0
   redis> PFCOUNT  databases                # 元素估计数量没有变化
   (integer) 3
   redis> PFADD  databases  "PostgreSQL"    # 添加一个不存在的元素
   (integer) 1
   redis> PFCOUNT  k1   k2                  # 估计数量增一

   redis> PFADD hll1 foo bar zap a
   (integer) 1
   redis> PFMERGE hll3 databases hll1
   "OK"
   redis> PFCOUNT hll3
   (integer) 7
   ```

#### 理论支持

1. 伯努利试验
   - _2^k_max =N: `n: 伯努利次数` + `某次过程中第一次出现正面是是第几次[k]` + `k_max: n次伯努利中k的最大值`_ || _2^k =N: k 次连续为反面的次数, N 包硬币的次数_
   - hll 的基本思想: 利用集合中数字的比特串第一个 1 出现位置的最大值来预估整体基数
   - 节约空间, 时间, 性能: 12k[稠密矩阵] 的内存就可以统计 2^64 个数据[误差率 0.81%]: 计数比较小的时候, 存储空间采用系数矩阵, 占用空间很小{小于 12kb}
   - 统计的数据不是精确的[有一定的误差], 但是此业务是允许的
2. hll 会把 key hash[MurmurHash] 成 64bit: **每一个 bit 都可以理解为 伯努利过程**
3. 为了减少误差引入桶的概念进来: 2^14 个, 做调和平均数等操作
   - `2^14 * 6 bit= 12k`
   - 数据个数: `2^6=64 => 2^64 个基数`
   - 不是一下都初始化出来的, 有稀疏的概念

#### explain

1. add
   - hash => 64bit
   - 【这个问题待定】取前 14 位作为 index **找到对应的桶**[一个]: 所以需要 2^14 个桶
   - `后50位中取第一个出现 1 的位作为值, 如果值大于旧值就更新`: 位数最大值是 50 **所以用 6bit 能够存储**`
   - count > 32 spare 转换成 dense 实现方式
2. count:
   - count 之后是会缓存起来的, add 会使缓存失效
   - count 本质就是公式的计算
     ![avatar](/static/image/db/redis-hll.png)
3. 数据结构

   - 基于以上数学原理的了解, 实际上需要存储的是数字 k
   - 为了解决误差问题, 分成了多个桶, 其中多桶解决误差问题: 2^14 个桶(完全为了解决误差)
   - 每个桶存储 6bit 存储能表示的最大值=2^6 = 64 完全能够存下 50
   - 基数的最大值: 2^64 ==> 一个桶最大值是 64, 相当于公式中的 k 的最大值是 64
   - 计算机中最小存取单位是 1byte=8bit, redis 为了极致利用内存, 会根据 offset 判断是否取上一个或下一个进行位运算, 得到 k, 取值场景有:
     - `[6,2][4,4][2,6][6,2][4,4][2,6][6,2][4,4][2,6][6,2][4,4][2,6]`

   ![avatar](/static/image/db/redis-hll-flow.png)
   ![avatar](/static/image/db/redis-store.png)

### geo

1. redis 的 GEO 类型的底层数据结构用的就是 Sorted Set 来实现

   - redis 采用业界广泛使用的 GeoHash 编码: 分别对经度和纬度编码, 最后再把经纬度各自的编码组合成一个最终编码
   - GeoHash 算法将二维的经纬度数据映射到一维的整数: 所有的元素都将在挂载到一条线上, **距离靠近的二维坐标映射到一维后的点之间距离也会很接近**
   - GeoHash 计算经度编码 || 纬度

     ```js
     // 经度 169.99 ==> 1100
     169.99 属于右分区, 使用 1 表示第一次分区编码
     再将 169.99 经过第一次划分所属的 [0, 180] 区间继续分成 [0, 90) 和 [90, 180], 169.99 依然在右区间, 编码 1
     将[90, 180] 分为[90, 135) 和 [135, 180], 这次落在左分区，编码 0
     // ...
     ```

     - GeoHash 合并经纬度编码, 作为 SortedSet 的权重值实现排序

     ```js
     // 经纬度编码分别是 11011(35.679) 和 00101(114.020)
     经纬度(35.679, 114.020)  ==> 1010011011 // 精度第一位 纬度第一位 精度第2位 纬度第2位 ...
     ```

2. LBS(Location Based Services) 附近的人核心思想如下

   - 以 "我" 为中心, 搜索附近的 Ta
   - 以 "我" 当前的地理位置为准, 计算出别人和 "我" 之间的距离
   - 按 "我" 与别人距离的远近排序, 筛选出离我最近的用户

3. mysql 实现: 不适合高并发

   - 通过 "我" 区域来过滤出有限「女神」坐标数据
   - 再对矩形区域内的数据进行全量距离计算(半径 R)再排序: sql

4. geo

   ```shell
   # 添加地理位置
   geoadd girl:location 13.361389 38.115556 "苍井空" 15.087269 37.502669 "波多野结衣"
   # 半径圆内的用户: (15, 37) 为中心 00km 内的所有人 近距离排序 且只取1个
   georadius girl:location 15 37 200 km ASC COUNT 1  [WITHCOORD/WITHDIST]
   # 用户下线
   ZREM girl:location "苍井空"
   ```

   |      command      |          function          |               sample               |
   | :---------------: | :------------------------: | :--------------------------------: |
   |      GEODIST      |       两点之间的距离       | GEODIST KEY member1 member2 [unit] |
   |      GEOHASH      |        返回 geohash        |         GEOHASH KEY member         |
   |      GEOPOS       |       返回经纬度位置       |         GEOPOS KEY member          |
   | GEOREDIUSBYMEMBER | 半径圆内的用户: 用户为中心 | GEOREDIUSBYMEMBER KEY member 300 m |

5. 使用注意

   - 在地图应用中, 车的数据、餐馆的数据、人的数据可能会有百万千万条, 如果使用 Redis 的 Geo 数据结构, 它们将全部放在一个 zset 集合中
   - 在 redis 的集群环境中, 集合可能会从一个节点迁移到另一个节点, 如果单个 key 的数据过大, 会对集群的迁移工作造成较大的影响
   - 在集群环境中单个 key 对应的数据量不宜超过 1M, 否则会导致集群迁移出现卡顿现象, 影响线上服务的正常运行
   - **所以建议 Geo 的数据使用单独的 Redis 集群实例部署**

## others

- N/A
