## 慢查询

![avatar](/static/image/db/redis-performance-ckecklist.png)

- 比如 bigkey 导致 api 慢速返回, 导致连接迟迟不能提交, 连接池爆炸, 应用服务器雪崩
- redis 命令都应该超快: 抗并发 || 毫米级(3ms)
- 慢定义: 运行的延迟是基线性能的 2 倍以上, 就可以判定 Redis 性能变慢

1. 基线测试:

   ```shell
   # server 延迟测试: 参数 100 是测试将执行的秒数
   # 在 server 端运行: 可以避免网络影响
   redis-cli --intrinsic-latency 100

   redis-benchmark -t set -q
   # -P 参数: 表示单个管道内并行的请求数量
   redis-benchmark -t set -P 3 -q
   ```

2. **慢指令**监控: 命令的时间复杂度 `O(1) 和 O(log N)`

   - 全量操作[O(N)]: HGETALL/SMEMBERS
   - 聚合操作[O(N)]: SORT/LREM/SUNION
   - 慢查询 Redis 慢日志功能查出慢命令: 配置文件 slowlog{超过 10ms[命令执行时间] 则会被记录}

     ```shell
     # 设置 slowlog 慢查询: <0 则不记录, =0记录全部
     6379> redis-cli CONFIG SET slowlog-log-slower-than 6000
     # slowlog-max-len(1k+): redis 记录慢查询的条数(FIFO)

     # 查看慢查询的命令
     6379> SLOWLOG get 2

     # 1) 1) (integer) 6                      # 这个 slowlog 出现的序号
     #    1) (integer) 1458734263             # 执行时的 Unix 时间戳
     #    2) (integer) 74372                  # 查询执行微秒数
     #    3) 1) "hgetall"                     # 查询的命令和参数
     #       1) "max.dsp.blacklist"
     ```

   - ~~latency-monitor[延迟监控]工具~~: 以秒为粒度监控各种事件的发生频率, 忠实的打印 Redis 中的所有请求{包括时间信息, Client 信息, 命令以及 Key 信息}

     ```shell
     # 设置延迟阈值(单位毫秒): 比如我们根据基线性能（3ms）的 3 倍设置阈值为 9 ms
     CONFIG SET latency-monitor-threshold 9

     6379> debug sleep 2
     6379> latency latest

     # 1) 1) "command"                        # 事件的名称
     # 2) (integer) 1645330616                # 最新延迟的 Unix 时间戳
     # 3) (integer) 2003                      # 时间延迟
     # 4) (integer) 2003                      # 该事件的最大延迟
     ```

   - top/htop/prstat: 如果 CPU 使用率很高而流量不高, 通常表明使用了慢速命令

3. 慢查询解决

   - 网络通信导致的延迟: pipeline 解决网络开销{`发送命令－〉 命令排队 －〉 命令执行－〉 返回结果`}
   - 集中过期默认都是主线程阻塞下工作的: lazyfree-xx 可以配置
   - 慢指令导致的延迟:

     1. 在集群中将 O(n) 的操作放到 slave 上执行|| 或者客户端
     2. 使用增量迭代的方式, 避免一次查询大量数据: SCAN、SSCAN、HSCAN 和 ZSCAN + 禁用 keys 等命令

   - Fork 生成 RDB 导致的延迟: 生成 rdb 文件(cow)时 fork 操作, 会阻塞内存

     1. fork 会涉及到复制大量链接对象
     2. [变慢]一个 24 GB 的大型 Redis 实例需要 24 GB / 4 kB \* 8 = 48 MB 的内存页表: 执行 bgsave 时, 这将涉及分配和复制 48 MB 内存
     3. [解决]从库加载 RDB 期间无法提供读写服务, 所以主库的数据**容量大小控制在 2~4G 左右**, 让从库快速的加载完成
     4. info 命令: 查看最后一次 fork 执行的耗时 latest_fork_usec

   - 内存大页: **大页会导致 fork 变快, 但是 cow 时需要 copy 的数据变大**

     1. 常规的内存页是按照 4 KB 来分配, Linux 2.6 之后开始支持大页机制(2M)
     2. [变慢]生成 RDB 快照时的 cow, 在此大页情况下, 就会多 copy 很多内存[变慢]
     3. [解决]禁用 Linux 内存大页(**默认是开启的**): `echo never > /sys/kernel/mm/transparent_hugepage/enabled`

   - 实例内存达到上限: 写入新的数据之前须先从实例中踢出一部分数据{默认阻塞的}, 让整个实例的内存维持在 maxmemory 之下
   - swap 操作系统分页: 涉及磁盘读写(慢)

     1. swap: 物理内存不够时, 将部分内存上的数据交换到 swap 空间上, 以便让系统不会因内存不够用而导致 oom 或者更致命的情况出现
     2. SWAP OUT: OS 会把内存中暂时不用的数据交换出去, 放在 SWAP 分区中
     3. SWAP IN: 把 SWAP 分区中的数据交换回物理内存中
     4. 发生 swap: Redis 使用了比可用内存更多的内存 || 其他进程占用内存, 导致 Redis 获得的内存减少, 触发了 swap
     5. 查看是否发生了 swap

        ```shell
        redis-cli info | grep process_id  # process_id:13160

        cd /proc/13160
        # smaps 描述进程的内存布局
        cat smaps | egrep '^(Swap|Size)'

        # Size:                  4 kB
        # Swap:                  0 kB   # 没有发生 swap
        # Size:             720896 kB
        # Swap:                 12 kB   # 发生 swap, 12k 可以接受
        ```

     6. 如果 Swap 是 0 kb/零星的 4k, 则可以接受; 当出现百 MB/ GB 时, 内存压力很大, 很有可能会变慢
     7. [解决] 生配置 || server 只运行 redis || 用集群{加分片 server}

   - AOF 和磁盘 I/O 导致的延迟

     1. [变慢`{bgrewrite 遇上了 aof write}`]appendfsync no/everysec/always 涉及到刷盘到磁盘{慢} + 子进程正在执行 AOF rewrite + 其他进程使用了系统资源
     2. [解决] no/everysec + no-appendfsync-on-rewrite 设置为 yes, 表示在 AOF 重写时, 不进行 fsync 操作(aof write 操作)

   - expires 淘汰过期数据

     1. 惰性删除
     2. [变慢]定时删除: **删除是阻塞的** + 触发(大量同时到期的 key 可能会导致性能波动)
     3. [解决] EXPIREAT 加上一个一定大小范围内的随机数, 也能避免雪崩

   - [bigkey](./99.question.md)
   - 降低主从库全量同步的概率
   - 客户端频繁的短连接

## 监控 info

1. [监控内存](./05.memory.md#查看)
2. 性能指标：Performance + redis-benchmark

   |           Name            |      Description       |
   | :-----------------------: | :--------------------: |
   |          latency          |       监控慢指令       |
   | instantaneous_ops_per_sec |  平均每秒处理请求总数  |
   |   hit rate(calculated)    | 缓存命中率[计算出来的] |

3. 基本活动指标：Basic activity

   |            Name            |        Description         |
   | :------------------------: | :------------------------: |
   |     connected_clients      |        客户端连接数        |
   |       conected_laves       |         slave 数量         |
   | master_last_io_seconds_ago | 最近一次主从交互之后的秒数 |
   |          keyspace          |   数据库中的 key 值总数    |
   |        backlog_size        |      复制积压缓冲大小      |

4. 持久性指标: Persistence

   |            Name            |            Description             |
   | :------------------------: | :--------------------------------: |
   |     rdb_last_save_time     |   最后一次持久化保存磁盘的时间戳   |
   | rdb_changes_sice_last_save | 自最后一次持久化以来数据库的更改数 |

5. 错误指标：Error

   |              Name              |               Description               |
   | :----------------------------: | :-------------------------------------: |
   |      rejected_connections      | 由于达到 maxclient 限制而被拒绝的连接数 |
   |        keyspace_misses         |      key 值查找失败(没有命中)次数       |
   | master_link_down_since_seconds |     主从断开的持续时间（以秒为单位)     |
   |  rdb_changes_since_last_save   |           主从断开的持续时间            |
   |        sync_partial_err        |        主从半同步复制失败的次数         |

6. [info result](https://github.com/Alice52/issue/issues/53#issuecomment-1140399517)

## practice

1. 每天每一个抢购商品只能买一次, 并且全场抢购商品总购买次数不允许超过 5 次
2. version 1

   ```shell
   # hash结构: field表示购买的商品ID, value表示购买次数
   hset mall:sale:freq:ctrl:860000000000001 599055114591 1
   hset mall:sale:freq:ctrl:860000000000001 599055114592 2
   expire mall:sale:freq:ctrl:860000000000001 3127 # 设置过期时间

   set mall:total:freq:ctrl:860000000000001 3
   expire mall:total:freq:ctrl:860000000000001 3127 #设置过期时间
   ```

3. version 2: 利用 hmset 命令将两条 hmset 命令合二为一

   ```shell
   hmset mall:sale:freq:ctrl:860000000000001 599055114591 1 599055114592 2
   expire mall:sale:freq:ctrl:860000000000001 3127

   setex mall:total:freq:ctrl:860000000000001 3127 3
   ```

4. version 3: pipeline + 需要 2 次网络交互

   ```shell
   # 这两条命令的key都是一样的, 肯定在同一个slot上
   pipeline(
     hmset mall:sale:freq:ctrl:860000000000001 599055114591 1 599055114592 2
     expire mall:sale:freq:ctrl:860000000000001 3127
   )

   setex mall:total:freq:ctrl:860000000000001 3127 3
   ```

5. version 4: 使用 hashtag 控制 key 在某一个 server 上

   ```shell
   # 使用 hashtag 时: 一定要注意不能把key的离散性变得非常差
   # mall:sale:freq:ctrl:860000000000001: 很明显这种key由于与用户相关, 所以离散性非常好
   # mall:sale:freq:ctrl:{860000000000001}: key还是与用户相关, 所以离散性依然非常好
   # mall:{sale:freq:ctrl}:860000000000001： 其{}中的内容完全一样所有的key都会落在同一个slot上, 导致整个Redis集群出现严重的倾斜问题
   pipeline(
     hmset mall:sale:freq:ctrl:${860000000000001} 599055114591 1 599055114592 2
     expire mall:sale:freq:ctrl:${860000000000001} 3127
     setex mall:total:freq:ctrl:${860000000000001} 3127 3
   )
   ```

## checklist

1. 获取当前 Redis 的基线性能
2. 开启慢指令监控, 定位慢指令导致的问题
3. 找到慢指令: 慢日志 || monitor
4. 将实例的数据大小控制在 2-4GB, 避免主从复制加载过大 RDB 文件而阻塞
5. 禁用内存大页, 采用了内存大页, 生成 RDB 期间, 即使客户端修改的数据只有 50B 的数据, Redis 需要复制 2MB 的大页。当写的指令比较多的时候就会导致大量的拷贝, 导致性能变慢
6. Redis 使用的内存是否过大导致 swap
7. AOF 配置是否合理, 可以将配置项 no-appendfsync-on-rewrite 设置为 yes, 避免 AOF 重写和 fsync 竞争磁盘 IO 资源, 导致 Redis 延迟增加
8. bigkey 会带来一系列问题, 我们需要进行拆分防止出现 bigkey, 并通过 UNLINK 异步删除
9. hotkey 问题
10. 可能原因列表
    - 如果请求量并不大, 但 CPU 使用率很高, 很有可能是使用了复杂度高的命令: 少用 & 每次少操作点数据
