![avatar](/static/image/db/redis-interview-overview.png)

### 0. memcached vs redis

|              |            redis             |     memcached      |
| :----------: | :--------------------------: | :----------------: |
|   数据类型   |       5+n 多种数据类型       |   string/二进制    |
|  value 的值  |           max-512m           |       max-1m       |
| 持久化(安全) |          y(aof/rdb)          | n(纯内存-重启丢失) |
|  使用(操作)  | 封装很多 api(计算向数据移动) |    crud/命令少     |
|     事务     |          y(a[n]cid)          |         n          |
|      mq      |  y(stream/list/zset/pubsub)  |         n          |
|     集群     |          有原生集群          |    无(有第三方)    |
|    分布式    |              y               |    n(单机内存)     |
|    原子性    |           lua/命令           |        _n_         |
|   线程模型   |          单核心线程          |       多线程       |
|   io 模型    |  非阻塞的多路复用 io(epoll)  |     非阻塞 io      |
|    事件库    |       自封装的 aeevent       |  贵族的 libevent   |
|   删除策略   |     惰性删除 + 定期删除      |      惰性删除      |
|     速度     |             超快             |         快         |

### [1. redis 为什么快](./02.thread-io.md)

1. 纯内存操作 vs 磁盘
2. redis 本质就是一个全局哈希表 + o(1) + rehash + 渐进式
3. 多路复用的非阻塞 io: epoll + 事件分发器 + 不会阻塞到某个连接上
4. 单线程模型: 集群/持久化/异步删除都是其他线程做 + 单线程输入计算输出[6.x 独立出入输出] + cpu 不是瓶颈 + 单线程的好处
5. redis 很多用 hash 结构 + 一些特殊的数据结构
   - 对数据存储进行了优化: 压缩表 + 跳表 + quicklist + intset + sds 等等
6. 根据实际存储的数据类型选择不同编码

### 2. 穿透&击穿&雪崩

1. 缓存穿透: 查询一个不存在（db）的 key, 缓存不能命中, 数据库也没有记录[无法缓存], 导致每次都要查数据库, `缓存失效`

   - 做严格的限制, 尽量过滤无效的请求
   - solution: 缓存 null`[解决的是使用某个 key 的大量并发]` 且加短暂的过期时间`解决内存`, 此时如果被攻击使用布隆过滤器
   - [布隆过滤器`说没有一定没有`](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

     ![avatar](/static/image/db/redis-bloomflter.png)

     1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
     2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

        ![avatar](/static/image/db/redis-bloom-filter.png)

     3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
        - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
     4. 判断的时候
        - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
        - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 则判断为可能存在

2. 缓存击穿: 某个 key(db 有) 是高频热点, 但是在大并发下下缓存过期或不存在

   - keyworkd: 单一热点数据, 高并发, 数据失效(或不存在)
   - solution: 加分布式锁, 大并发下只让一个线程去查数据库, 其他人等待, 查到以后释放锁; 其他线程(阻塞)获取到锁, 先查询缓存(热点数据可以不设置失效时间或设置长一点[加个随机事件])
   - **数据预热**

3. 缓存雪崩: 大量的同类型的 key 同时失效或者 redis 挂了, 请求压力都转到了数据库 [mysql 挂应用服务挂]

   - solution: 在原有的失效时间上添加一个随机数以降低重复概率/永不失效: `分治思想`
   - 服务熔断 + 限流降级
     1. 熔断: 当从缓存获取数据发现异常, 则直接返回错误数据给前端: 防止所有流量打到数据库导致宕机
     2. 限流: 缓存失效后, 通过加业务锁或者队列来控制读数据库写缓存的线程数量, 对某个 key 只允许一个线程查询数据和写缓存, 其他线程等待
   - akf 分治: 让其不同的 key 落在不同的分片上执行加锁查数据库的逻辑
   - [挂了]redis 高可用: 哨兵 + cluster

4. **可以考虑在业务层面上解决 12306**

### 3. 海量数据下怎么快速查找一条记录

1. 使用布隆过滤器, 快速过滤不存在的数据[spring cache 中有笔记]
2. 在 redis 中建立数据缓存
   - 以普通的字符串存储(user-id -> user object) / 以 hash 存储(user-id k->v)`[会存在大量的 key]`
   - 使用一个 hash 存储所有的数据(user-info user-id->uo)`[key 是减少了, 一个 可以存 2^32-1 个键值对]`
   - 存在缓存穿透: 由于布隆过滤器的误判导致的
   - 存在缓存击穿: key 失效导致的, 可以使用锁机制[一个线程写缓存]
3. 查询优化
   - redis 数据是按槽位计算分配存储空间的
   - ~~自己实现槽位计算, 自己计算数据在那台机器上, 然后进行查找~~

#### 布隆过滤器: 基于概率的数据结构

1. 当布隆过滤器说某个值存在时,这个值可能不存在; 当它说不存在时, 那就肯定不存在
2. 特点
   - 一个非常大的二进制位数组(数组中只存在 0 和 1）
   - 拥有若干个哈希函数(hash function）
   - 在空间效率和查询效率都非常高
   - **布隆过滤器不会提供删除方法**, 在代码维护上比较困难
     - 删除的话就需要在每个 bit 位上记录出现次数: 带有计数器的布隆过滤器会占用更大的空间
3. 要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:
   - 哈希函数的好坏
   - 存储空间大小
   - 哈希函数个数

#### [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

   ![avatar](/static/image/db/redis-bloom-filter.png)

3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
   - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
4. 判断的时候
   - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
   - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 则判断为可能存在

### 4. 如何优化 redis 的性能

1. 客户端优化
   - pipeline
   - 连接池
2. 淘汰机制
   - 内存大小
   - 过期时间
   - 淘汰策略
3. key 与 value 的优化: big key`redis-cli --bigkeys || ui tools` + big value: `10k 1w` 打满网卡
   - key 的设计: 可读性 + 可管理性[前缀名 :] + 简洁性[key 本身不要太长] + 不要包含特殊字符
   - value 的设计: 拒绝 bigkey[慢查询||打满网卡] + 选择合理的数据类型[hash 不会序列化, 频繁修改的数据可以使用 hash]
   - 尽量都设置过期时间
4. 禁止使用耗时操作
   - `keys *`: scan
   - big key delete
   - flushall
5. 慢查询优化
   ```shell
   # 1. 配置文件中开启 redis 慢查询监控
   slowlog-log-slower-than 10000000 # 耗时
   slowlog-max-len 128 # 内存
   # 2. 查看慢查询
   slowlog get count # id + start-time + nan-consuming + command
   ```
6. 内存可视化:
   - dump.rdb
   - [rdr-windows.exe-github](https://github.com/xueqiu/rdr)
   - java 的序列化策略很影响性能
   - redis 内存空间优化: `strlen`
   - memory usage username # bits

### 5. bigkey 问题

1. 带来的影响:

   - key 比较大(client 发现变慢), 查询和传输比较耗时[单线程阻塞执行], 则可能导致连接不能快速释放[could not get a resource from the pool], **进而导致服务系统雪崩**
   - 引发 oom: 写阻塞 || 导致重要的 key 被驱逐
   - cluster 下导致每个 node 的数据量不一致: 不均衡{资源难以调配}
   - 吃带宽, 影响其他服务, 也影响并发[单线程阻塞写出]
   - 删除一个 bigkey[阻塞] 造成主库较长时间的阻塞并引发同步中断或主从切换

2. 是什么(定义): stringvalue(max 512m) > 1024k || element size > 10240 || list/hash 等元素不多但是大

3. 大 key 常规原因: 业务规划不足 || redis 不正确的使用 || 无效数据的堆积

   - 将 redis 用在并不适合其能力的场景, 造成 key 的 value 过大: 使用 string 类型的 key 存放大体积二进制文件型数据`[大key]`
   - 业务上线前规划设计考虑不足没有对 key 中的成员进行合理的拆分, 造成个别 key 中的成员数量过多`[大key]`
   - 没有对无效数据进行定期清理, 造成如 hash 类型 key 中的成员持续不断的增加`[大key]`
   - 使用 list 类型 key 的业务消费侧代码故障, 造成对应 key 的成员只增不减`[大key]`

4. 找出 redis 中的大 key: redis-rdb-tools || 内存可视化

   - 使用 redis 内置功能发现大 key:
     1. redis 内置命令: `memory usage命令来帮助分析key的内存占用` + 自带的各种数据类型的长度获取
     2. redis-cli: `大key: redis-cli --bigkeys`
     3. 使用 monitor 命令在紧急情况时找出热 key: 尽量不要用{对于一个已处于高压状态的 redis, monitor 可能会起到雪上加霜的作用}
   - 使用开源工具发现大 key: redis-rdb-tools
     1. 离线分析代表着分析结果的较差时效性
     2. 对于一个较大的 rdb 文件, 它的分析可能会持续很久很久
   - 依靠公有云的 redis 分析服务发现大 key

   ```shell
   # bigkeys仅能分别输出redis六种数据结构中的最大key
   # 如果你想只分析string类型或是找出全部成员数量超过10的hash key
   # 那么bigkeys在此类需求场景下将无能为力
   redis-cli --bigkeys # 粗糙
   memory usage username # bits

   # ui tools github

   # 可以使用 scan 脚本去一点一点扫描计算并获取 key 的大小
   ```

5. 大 key 的解决方案

   - 如果业务数据就是大, 可以考虑压缩[gzip{并发有损}]: 这样压力就转嫁到应用服务器了
   - 如果集合类型的元素的确很多, 可以将一个大集合拆分成多个小集合来保存
   - protostuff 和 kryo 这两种序列化方法, 就要比 java 内置的序列化方法效率更高: 二进制数据+可读性太差
   - 所以, 一般还是会存 json/xml, 但是可以使用 snappy/gzip 进行压缩
   - 将不适合存储在 redis 的数据存放至其它存储, 并在 redis 中删除此类数据[unlink/zscan/***]
   - 删除: 4.0 之后提供异步删除 key 的 **unlink**, 将 key 的释放放在 background io 的单独的子线程处理, 减少对主线程的影响; 4.0 之前使用`hscan scan ltrim zscan sscan`
   - 时刻监控 redis 的内存水位: redis 内存使用率超过 70% || redis 内存 1 小时内增长率超过 20%等
   - 业务问题导致的 list 元素只增加, 不减少: 修改 code
   - 如果是上云的服务: 可以使用提供的服务

### 6. 热 key 问题

1. 定义: 在某个 key 接收到的访问次数, 显著高于其它 key 时, 我们可以将其称之为热 key

   - 访问次数显著高于其它 key: 某 redis 实例的每秒总访问量为 10000, 而其中一个 key 的每秒访问量达到了 7000
   - 带宽占用显著高于其它 key: 对一个拥有上千个成员且总大小为 1mb 的 hash key 每秒发送大量的 hgetall
   - cpu 时间占用显著高于其它 key: 对一个拥有数万个成员的 zset key 每秒发送大量的 zrange

2. 缺点

   - 热 key 占用大量的 redis cpu 时间使其性能变差并影响其它请求
   - redis cluster 中各 node 流量不均衡造成 redis cluster 的分布式优势无法被 client 利用: **一个分片负载很高而其它分片十分空闲**从而产生读/写热点问题
   - 在抢购/秒杀活动中, 由于商品对应库存 key 的请求量过大**超出 redis 处理能力**造成超卖
   - 热 key 的请求压力数量**超出 redis 的承受能力造成缓存击穿**, 此时大量强求将直接指向后端存储将其打挂**并影响到其它业务**

3. 热 key 的常见产生原因: 访问突增等

   - 预期外的访问量陡增, 如突然出现的爆款商品、访问量暴涨的热点新闻、直播间某大主播搞活动带来的大量刷屏点赞、游戏中某区域发生多个工会间的战斗涉及大量玩家等`[热key]`

4. 找出 redis 中的大 key 与热 key

   - 使用 redis 内置功能发现热 key:
     1. redis-cli: `热key: redis-cli --hotkeys`{必须是 lfu}
     2. 通过业务层定位热 key: 在业务层增加相应的代码对 redis 的访问进行记录并异步汇总分析{准确及时的分析出热 key, 缺点为业务代码复杂度的增加, 同时可能会降低一些性能}
   - 依靠公有云的 redis 分析服务发现热 key

5. 热 key 的解决方案

   - cluster 中各 node 流量不均衡造成: 将热 key 进行复制并迁移至其他 node

     1. 例如为热 key foo 复制出 3 个内容完全一样的 key 并名为 foo1, foo2, foo3, 然后将这三个 key 迁移到其他 node 来解决单一 node 的热 key 压力
     2. 客户端就可以访问 foo/foo1/foo2/foo3
     3. 缺点: 需要联动修改代码 + key 一变多带来了数据一致性挑战 + 因此只能作为临时方案使用

   - 使用读写分离架构: 通过不断的增加从节点来降低每个 redis 实例中的读请求压

     1. 读写分离架构在业务代码复杂度增加的同时, 同样带来了 redis 集群架构复杂度的增加
     2. 我们不仅要为多个从节点提供转发层[如 proxy/lvs 等]来实现负载均衡
     3. 还要考虑从节点数量显著增加后带来的故障率增加的问题, redis 集群架构变更的同时为监控、运维、故障处理带来了更大的挑战
     4. 读写分离架构会产生不可避免的延迟 + 会有读取到脏数据的问题
     5. **因此, 在读写压力都较大写对数据一致性要求很高的场景下, 读写分离架构并不合适**

   - 超高读压力: 通过超高效的 proxy 层来做: proxy 做缓存+多实例(负载)
   - 超高写压力: 通过对多个实例一起写, 然后想办法将数据汇总

### 7. 假如 redis 里面有 1 亿个 key, 其中有 10w 个 key 是以某个固定的已知的前缀开头的, 如果将它们全部找出来

1. keys reg: **单线程**会 block 所有的 redis 操作
2. scan: **时间比他长**, 但是被分散开了, 可能重复[需要去重*或丢失*]

### 8. 怎么保证 redis 中的数据是热点数据

1. key 的过期时间: 时间段 || 到指定时间
   - 写(包括重写)时除非指定过期时间, 否则就是-1
   - 访问是不会延长时间的
2. 缓存淘汰机制

### 9. 使用过程中遇到的问题

1. 和泛型结合对产生类型问题: redis 没有类型
2. redis map integer 的泛型擦除问题

### 10. 如何做好缓存预热

1. 提前把数据放入 redis
2. code 上要处理`穿透&击穿&雪崩`问题

### 11. 超高并发处理: 1kwqps

1. 将 key 拆分成多个独立的小 key, 并将其放入不同的 server
2. 本质就是分治

### 12. redis 为什么使用跳表而不是红黑树(或者 avl 树)

0. overview: 复杂且收益没有那么高
1. 范围查找时, 平衡树比跳表操作要复杂

   - 在平衡树上, 找到指定范围的小值之后, 还需要以中序遍历的顺序继续寻找其它不超过大值的节点{并易实现}
   - 在跳表上进行范围查找, 只需要在找到小值之后, 对第 1 层链表进行若干步的遍历即可

2. 插入和删除操作

   - 平衡树可能引发子树的调整, 逻辑复杂
   - 跳表的插入和删除只需要修改相邻节点的指针, 操作简单又快速

3. 内存占用上: 跳表比平衡树更灵活一些(元素存两遍空间花销)

   - 平衡树每个节点包含 2 个指针[分别指向左右子树]
   - 跳表每个节点包含的指针数目平均为 1/(1-p): redis - 1.33 个指针

4. 查找单个 key: 跳表和平衡树的时间复杂度都为 o(log n)
5. 实现难度上来比较: 跳表比平衡树要简单得多

### 13. redis 是如何判断数据是否过期

1. redisdb 对象中有 `*expire`: 指向 过期字典[可以看作是 hash 表]来保存数据过期的时间
2. 过期字典的键指向 redis 数据库中的某个 key(键), 过期字典的值是一个 long 类型的整数
3. 这个整数保存了 key 所指向的数据库键的过期时间[毫秒精度的 unix 时间戳]

### [14. 数据一致性问题](./12.consistency.md)

### 15. redis 在秒杀场景的应用

1. redis 主要是起到`选拔流量`的作用, 记录商品总数, 还有就是已下单数(分布式-锁), 等达到总数之后拦截所有请求: 可以多放些请求进来, 然后塞入消息队列
2. 蚂蚁金服的云 redis 提到消息队列可以用 redis 来实现, 但我觉得更好的方式是用 kafka 这种标准消息队列组件

### ~~16. redis 的并发竞争问题如何解决~~

1. redis 为单进程单线程模式, 采用队列模式将并发访问变为串行访问
2. redis 本身没有锁的概念, redis 对于多个客户端连接并不存在竞争
3. 但是在 jedis 客户端对 redis 进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题, 这些问题均是由于客户端连接混乱造成. 对此有 2 种解决方法:
   - 客户端角度: 为保证每个客户端间正常有序与 redis 进行通信, 对连接进行池化, 同时对客户端读写 redis 操作采用内部锁 synchronized/lock
   - 服务器角度: 利用 setnx 实现锁
