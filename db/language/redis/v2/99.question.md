### [1. redis 为什么快](./02.thread-io.md)

1. 纯内存操作 vs 磁盘
2. redis 本质就是一个全局哈希表 + O(1) + rehash + 渐进式
3. 多路复用的非阻塞 IO: epoll + 事件分发器 + 不会阻塞到某个连接上
4. 单线程模型: 集群/持久化/异步删除都是其他线程做 + 单线程输入计算输出[6.x 独立出入输出] + cpu 不是瓶颈 + 单线程的好处
5. redis 很多用 hash 结构 + 一些特殊的数据结构
   - 对数据存储进行了优化: 压缩表 + 跳表 + quicklist + intset + sds 等等
6. 根据实际存储的数据类型选择不同编码

### 2. 穿透&击穿&雪崩

1. 缓存穿透: 查询一个不存在（DB）的 Key, 缓存不能命中, 数据库也没有记录[无法缓存], 导致每次都要查数据库, `缓存失效`

   - 做严格的限制, 尽量过滤无效的请求
   - solution: 缓存 Null 且加`短暂的过期时间`[解决的是使用某个 key 的大量并发], 此时如果被攻击
   - [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

     1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
     2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

        ![avatar](/static/image/db/redis-bloom-filter.png)

     3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
        - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
        - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
     4. 判断的时候
        - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
        - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
        - 则判断为可能存在

2. 缓存击穿: 某个 Key(DB 有) 是高频热点, 但是在大并发下下缓存过期了 || 不存在

   - solution: 加锁, 大并发下只让一个线程去查数据库, 其他人等待, 查到以后释放锁; 其他线程获取到锁, 先查询缓存
   - **数据预热**

3. 缓存雪崩: 大量的 Key 的同时失效, 请求压力都转到了数据库, redis 挂了

   - solution: 在原有的失效时间上添加一个随机数以降低重复概率/永不失效
   - AKF 分治: 让其不同的 key 落在不同的分片上执行加锁查数据库的逻辑
   - redis 高可用
   - 限流降级: 缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个 key 只允许一个线程查询数据和写缓存, 其他线程等待。

4. **可以考虑在业务层面上解决 12306**

### 3. 海量数据下怎么快速查找一条记录

1. 使用布隆过滤器, 快速过滤不存在的数据[spring cache 中有笔记]
2. 在 redis 中建立数据缓存
   - 以普通的字符串存储(user-id -> user object) / 以 hash 存储(user-id k->v)`[会存在大量的 key]`
   - 使用一个 hash 存储所有的数据(user-info user-id->uo)`[key 是减少了, 一个 可以存 2^32-1 个键值对]`
   - 存在缓存穿透: 由于布隆过滤器的误判导致的
   - 存在缓存击穿: key 失效导致的, 可以使用锁机制[一个线程写缓存]
3. 查询优化
   - redis 数据是按槽位计算分配存储空间的
   - ~~自己实现槽位计算, 自己计算数据在那台机器上, 然后进行查找~~

#### 布隆过滤器: 基于概率的数据结构

1. 当布隆过滤器说某个值存在时,这个值可能不存在; 当它说不存在时, 那就肯定不存在
2. 特点
   - 一个非常大的二进制位数组(数组中只存在 0 和 1）
   - 拥有若干个哈希函数(Hash Function）
   - 在空间效率和查询效率都非常高
   - 布隆过滤器不会提供删除方法, 在代码维护上比较困难
     - 删除的话就需要在每个 bit 位上记录出现次数: 带有计数器的布隆过滤器会占用更大的空间
3. 要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:
   - 哈希函数的好坏
   - 存储空间大小
   - 哈希函数个数

#### [布隆过滤器](https://zhuanlan.zhihu.com/p/43263751): 将所有的 key 都维护在其中, 请求之前先判断一下

1. 是一个只存 0/1 的方便查找和插入且不能删除[且不能计数]的 bit 数组的数据结构
2. 布隆过滤器的性能: bit 数组的长度 & hash 算法的个数与散列程度

   ![avatar](/static/image/db/redis-bloom-filter.png)

3. 插入过程: [可以使用一个 bit 数组, 也可以使用多个 bit 数组]
   - 对指定的值进行 hash-f1, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f2, 最终得到一个 int 值[即该位置上的 bit 置为 1]
   - 对指定的值进行 hash-f3, 最终得到一个 int 值[即该位置上的 bit 置为 1]
4. 判断的时候
   - 对指定的值进行 hash-f1, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在,
   - 否则进行 hash-f2, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 否则进行 hash-f3, 最终得到一个 int 值, 若该位的 bit 值位、为 0 则不存在
   - 则判断为可能存在

### 4. 如何优化 redis 的性能

1. 客户端优化
   - pipeline
   - 连接池
2. 淘汰机制
   - 内存大小
   - 过期时间
   - 淘汰策略
3. key 与 value 的优化: big key`redis-cli --bigkeys || ui tools` + big value: `10k 1w` 打满网卡
   - key 的设计: 可读性 + 可管理性[前缀名 :] + 简洁性[key 本身不要太长] + 不要包含特殊字符
   - value 的设计: 拒绝 bigkey[慢查询||打满网卡] + 选择合理的数据类型[hash 不会序列化, 频繁修改的数据可以使用 hash]
   - 尽量都设置过期时间
4. 禁止使用耗时操作
   - `keys *`: scan
   - big key delete
   - flushall
5. 慢查询优化
   ```shell
   # 1. 配置文件中开启 redis 慢查询监控
   slowlog-log-slower-than 10000000 # 耗时
   slowlog-max-len 128 # 内存
   # 2. 查看慢查询
   slowlog get count # id + start-time + nan-consuming + command
   ```
6. 内存可视化:
   - dump.rdb
   - [rdr-windows.exe-github](https://github.com/xueqiu/rdr)
   - java 的序列化策略很影响性能
   - redis 内存空间优化: `strlen`
   - memory usage username # bits

### 5. bigkey 问题

1. find

   ```shell
   # ui tools github
   redis-cli --bigkeys
   memory usage username # bits

   # 可以使用 scan 脚本去一点一点扫描计算并获取 key 的大小
   ```

2. string value > 1024k || element size > 10240
3. 删除
   - 4.0 之后: 提供异步删除 key 的 unlink, 将 key 的释放放在 background io 的单独的子线程处理, 减少对主线程的影响
   - 4.0 之前: `hscan scan ltrim zscan sscan`

### 6. 假如 Redis 里面有 1 亿个 key, 其中有 10w 个 key 是以某个固定的已知的前缀开头的, 如果将它们全部找出来

1. keys reg: 单线程会 block 所有的 redis 操作
2. scan: 时间比他长, 但是被分散开了, 可能重复[需要去重]

### 7. 怎么保证 redis 中的数据是热点数据

1. key 的过期时间: 时间段 || 到指定时间
   - 写(包括重写)时除非指定过期时间, 否则就是-1
   - 访问是不会延长时间的
2. 缓存淘汰机制

### 8. 使用过程中遇到的问题

1. 和泛型结合对产生类型问题: redis 没有类型
2. redis map integer 的泛型擦除问题

### 9. 如何做好缓存预热

1. 提前把数据放入 redis
2. code 上要处理`穿透&击穿&雪崩`问题
