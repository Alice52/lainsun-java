## redis 实现 mq 功能: `内存级别的消息很大的话会占内存`

- mq 可以接受消息`生产者`, 保存[有序]下来`broker`, 等之后被**可靠{丢失(需要 ack 确认机制)}**消费{**自动通知客户端**}`consumer`

### pub/sub

![avatar](/static/image/db/redis-mq.png)

1. 发布订阅优点:

   - 典型的一对多的: `1:N`, 所有消费者都能同时消费到消息
   - 主动通知订阅者而不是订阅者主动轮询去读

2. 发布订阅缺点

   - 不能做到先放入队列之后再通知订阅者: 消息没有持久化, 不管订阅者是否收到消息, **消息都会丢失**
   - 没有消息的确认机制
   - 不支持多个消费者公平消费消息

### zset 队列

1. 生产者通过 zadd 创建消息时指定分数[可以确定消息的顺序]: 消费者通过 zrange 获取消息后进行消费, 消费完后通 zrem 删除消息
2. zset 优点: 保证了消息的顺序, **消费者消费失败后重新入队不会打乱消费顺序**
3. zset 缺点:

   - 不支持一对多消费,
   - **多个消费者消费时可能出现读取同一条消息的情况**[幂等]
   - 没有确认机制(丢消息)
   - 是订阅者主动轮询去读

4. zset 使用场景: 如 redisson 的 DelayQueue
   - 延迟队列: 拿时间戳作为 score, zrangebyscore 获取 N 秒前的数据消费, 之后删除

### List 实现 MQ

0. flow command

   ```shell
   # 生产者
   LPUSH key element[element...]

   # 消费者
      # 顺序消费: redis 单线程自保证
      # 实时消费: while (true) + BRPOP
      BRPOP queue 0
      # 消息可靠性 BRPOPLPUSH
      BRPOPLPUSH a a-backup
   ```

1. list 是一种线性的有序结构, 可以按照顺序存储元素, 能做到 FIFO
2. 生产者: LPUSH

   ```shell
   # 将消息插入到队列的头部: 如果 key 不存在则会创建一个空的队列再插入消息
   # 返回值是列表元素个数
   LPUSH key element[element...]
   ```

3. 消费者: RPOP

   ```shell
   # FIFO: 列表不存在或无元素是返回nil
   RPOP key

   # 实时消费: 0 表示一直阻塞等待
   BRPOP queue 0
   ```

   - MQ 是需要实时消费的: ~~`while(true) RPOP`~~ 这太消耗 cpu 资源[不合适]
   - 实时消费解决: **BRPOP 阻塞读取**, 消费者在在读取队列没有数据的时候自动阻塞, 直到有新的消息写入队列, 才会继续读取新消息执行业务逻辑
   - 重复消费[幂等]: 消息上设置 `全局 ID` 标识

4. 消息可靠性

   - 消费者从 List 中读取一条在消息处理过程中宕机了就会导致消息没有处理完成
   - 本质就是消费者在处理消息的时候崩溃了， 就无法再还原消息, **缺乏一个消息确认机制**
   - 解决方案: RPOPLPUSH, BRPOPLPUSH(阻塞)两个指令, 原子的从 List 从读取消息的同时把这条消息复制到另一个 List 中

     ```shell
     LPUSH queue java ruby
     # queue 中取出并放入 queue-backup
     BRPOPLPUSH queue queue-backup
     # 消费完成之后再删除 queue-backup 的消息
     ```

5. broker: redis

   - 生产者消息发送的很快, 而消费者处理速度慢就会导致消息堆积, 给 Redis 的内存带来过大压力[可能影响 redis 其他业务]

6. 总结

   - 使用: 在**消息量不大**的情况下使用 Redis 作为消息队列, 高性能的消息读写
   - 问题: 消息可靠性{缺乏消息确认机制 ack} + 消息堆积 + 消费组 + list 是线程结构[~~查询时需要遍历整个列表~~] + 需要主动轮询
   - 推荐: **5.x 的 Stream**

### Stream: 5.x

0. flow command

   ```shell

   # 消费者:
   XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] ID [ID ...]
      # 1. 云凌使用如下指令接收云山的命令
      # count 1: 表示每个流中最多读取的元素个数
      # BLOCK 0: 阻塞读取, 0 表示一直等待
      # ID: 消息 ID, 在读取消息的时候可以指定 ID, 并从这个 ID 的下一条消息开始读取, 0-0 则表示从第一个元素开始读取
      # XREAD COUNT 1 BLOCK 0 STREAMS 云岚宗 0-0

      # 2. 读取最新的阻塞消息
      # XREAD COUNT 1 BLOCK 0 STREAMS 云岚宗 $
   ```

1. Stream 简介

   - 专门为消息队列设计的数据类型, 支持多播的可持久化的消息队列{和其他数据结构一样支持 ha 所以也就可以高并发}
   - Stream 是一个包含 0 个或者多个元素的有序队列: 根据 ID 的大小进行有序排列
   - 还提供了消息的持久化和主从复制机制, 客户端可以访问任何时刻的数据, 并且能记住每一个客户端的访问位置, 从而保证消息不丢失

2. feature for mq: **消息会一直存在 stream 中**

   - 消息 ID 系列化生成
   - 消息的阻塞和非阻塞读
   - ACK 确认机制
   - **Consumer Groups 消费组**
   - 支持多播
   - ~~消息遍历~~

3. 消息 ID 系列化生成

   - 组成
     1. 当前毫秒内的时间戳
     2. 顺序编号: 从 0 为起始值, 用于区分同一时间内产生的多个命令
   - 通过将元素 ID 与时间进行关联, 并强制要求新元素的 ID 必须大于旧元素的 ID, **Redis 从逻辑上将流变成了一种只执行追加操作的数据结构**
   - 新的消息和事件只会出现在已有消息和事件之后: 就像现实世界里新事件总是发生在已有事件之后一样, 一切都是**有序**进行的

4. 生产者: XADD
5. 消费者: XREAD{不会消除消息}

   - 指定消费: stream 可以指定读取的消息 Id: 从该 Id 的下一条消息读取
   - 顺序消费: 每次读取后要记住返回的消息 ID, 下次调用 XREAD 就将上一次返回的消息 ID 作为参数传递到下一次调用
   - 不接受历史消息

     ```shell
     # 读取最新的阻塞消息
     XREAD COUNT 1 BLOCK 0 STREAMS 云岚宗 $
     ```

   - 消息 Id 指定:
     1. `0-0: 表示从第一位置开始消费`
     2. `$: 表示从最后一个位置开始消费[忽略历史消息]`
     3. `> : 表示从尚未被消费的消息开始读取`

6. 消息确认机制: ack{_也不会删除消息_}, 只是标识某消费组消费消息成功

   - xack

7. **ConsumerGroup**: 一定程度上破坏了消息的严格的顺序性

   - 允许用户将一个流从逻辑上划分为多个不同的流，并让 ConsumerGroup 的消费者去处理
   - 每一个 stream key 都是一个消息链表: 唯一 Id+内容
   - xread 读取消息是不会被删除的: 没有 ack, 需要配合消费组概念使用
   - 每个消费组都是独立的: 同一个 streamkey 可以被不同的消费组隔离的消费
   - 每个消费组都可以包含多个消费者: 有任何一个**消费者**消费完消息即可

     1. 消息只能被消费一次: last_deliverd_id 完成的
     2. **每个消费者都有一个 pending_ids: 存放消费了,但是没有 ack 的消息**
     3. 使用消费者的另一个目的可以让组内的多个消费者分担读取消息, 也就是每个消费者读取部分消息, 从而实现均衡负载

   - command

     1. XGROUP 用于创建、销毁和管理消费者组
     2. XREADGROUP 通过消费组从流中读取数据
     3. XACK 是允许消费者将待处理消息标记为已正确处理的命令
     4. XPENDING: 查看已读未确认消息{为了保证消费者在消费的时候发生故障或者宕机重启后依然可以读取消息, 每个都有 pendingids}

   - sample

     ```shell
     # 生产者: Stream 中的每个元素由键值对的形式组成, 不同元素可以包含不同数量的键值对
      # XADD streamName id field value [field value ...]
      #「*: 表示让 Redis 为插入的消息自动生成唯一 ID, 也可以自己定义
      # 返回 "1645936602161-0"
     XADD bossStream * name zhangsan age 26
     XADD bossStream * name lisi age 2
     XADD bossStream * name bigold age 40

     # 消费组创建: XGROUP CREATE STREAM_NAME GROUP_NAME start_id MKSTREAM
     # STREAM_NAME: queuename
     # GROUP_NAME: 消费者的名字
     # 0-0: 指定消费组在 Stream 中的起始 ID{从该Id之后读取} + $ 表示从最后一条开始读取[忽略历史数据]
     # MKSTREAM: 创建时 stream 不存在默认报错, MKSTREAM 可以自动床架 不存在的 streamkey
     XGROUP CREATE bossStream 青龙门 0-0 MKSTREAM
     XGROUP CREATE bossStream 六扇门 0-0 MKSTREAM

     # 消费: XREADGROUP GROUP groupName consumerName [COUNT n] [BLOCK ms] STREAMS streamName [stream ...] id [id ...]
     XREADGROUP GROUP 青龙门 consumer1 COUNT 1 BLOCK 0 STREAMS bossStream >  # 读取消费了 zhangsan
     XREADGROUP GROUP 青龙门 consumer2 COUNT 1 BLOCK 0 STREAMS bossStream >  # 读取消费了 lisi{zhangsan被消费过了[不会会一个消费组重复消费]}

     # 消费 ack: 表示消息确认消费, 删除 pending_ids 数据
     XPENDING bossStream 青龙门 # 可以看到有两个未确认消息, 此时如果宕机了
     XACK bossStream 青龙门 #1645957821396-0 #1645957838700-0
     XPENDING bossStream 青龙门 # 可以看到没有未确认消息{消息消费成功}

     # 使用另外的消费组消费: 可以从第一个开始消费
     XREADGROUP GROUP 六扇门 consumer2 COUNT 1 BLOCK 0 STREAMS bossStream >  # 读取消费了 zhangsan
     ```

   ![avatar](/static/image/db/redis-struct-stream-flow.png)
   ![avatar](/static/image/db/redis-struct-stream.png)
