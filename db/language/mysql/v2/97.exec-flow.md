## 关键字执行过程

### or

1. mysql 5.0 之前会导致索引失效
2. 之后的版本中引入了索引合并: 改善了一点效率(type: index_merge)

   - 把多条件查询(比如 or 或 and)的条件对多个索引分别进行条件扫描, 然后将它们各自的结果进行合并, 因此就可能不会导致索引失效的问题

3. exp

   ```sql
   -- idx_name + id is pri
   -- type: index_merge, extra: Using union(idx_name,PRIMARY); Using where
   explain select * from account_member where nickname = 'zack' or id=9;

   -- 此时 t || id || nickname 只要有一个没索引就会全表扫描
   explain select * from account_member where nickname = 'zack' or id=9 or t=xx;
   ```

### order by

0. 想获取到排好序的结果:

   - 对结果集进行排序的操作: 获取数据之后排序
   - 按照索引顺序扫描得出的结果自然是有序的: 在有序的数据上截取

1. overview: 2 个参数 + 1 建议 + 2 个特殊 + 正排倒排 + 1 注意

   - [一般不要改]sort_buffer_size: 确定内存中排, 磁盘上外排{归并排序}
   - [一般不要改]max_length_for_sort_data(1024): 确定是 全字段排序 || Rowid 排序
   - 1 建议: 善于使用副高索引
   - 2 个特殊: 无条件排序不会走索引{非覆盖索引} + **limit** 可能优先队列排序{filesort_priority_queue_optimization }
   - 正排倒排: 8.x
   - 1 注意: Using filesort 在高并发下一定会有问题

2. pre-env

   ```sql
   create table `staff` (
      `id` bigint ( 11 ) auto_increment comment '主键id',
      `id_card` varchar ( 20 ) not null comment '身份证号码',
      `name` varchar ( 64 ) not null comment '姓名',
      `age` int ( 4 ) not null comment '年龄',
      `city` varchar ( 64 ) not null comment '城市',
      primary key ( `id`),
      index idx_city ( `city` )
   ) engine = innodb comment '员工表';

   select name, age,city from staff where city = '深圳' order by age limit 10;
   ```

   ![avatar](/static/image/db/mysql-key-orderby-data.png)

3. 全字段排序: 需要的全部字段都放到 sort_buffer 中, 排序后就会直接从内存里面返回查询结果

   - sql flow

     1. MySQL 为对应的线程初始化 sort_buffer, 放入需要查询的 **name、age、city** 字段
     2. 从索引树 idx_city, 找到第一个满足 city='深圳’条件的主键 id, 也就是图中的 id=9
     3. 到主键 id 索引树拿到 id=9 的这一行数据, 取 name、age、city 三个字段的值, 存到 sort_buffer
     4. 从索引树 idx_city 拿到下一个记录的主键 id, 即图中的 id=13
     5. 重复步骤 3、4 直到 city 的值不等于深圳为止
     6. 前面 5 步已经查找到了所有 city 为深圳的数据, 在 sort_buffer 中, 将所有数据根据 age 进行排序
     7. 按照排序结果取前 10 行返回给客户端。

     ![avatar](/static/image/db/mysql-key-orderby-mem-flow.png)

   - 过程中 sort_buffer 如果满了则会使用 `磁盘临时文件辅助排序`: **optimzier_trace's number_of_tmp_files**
     ![avatar](/static/image/db/mysql-key-orderby-optra-disk.png)

     1. 从主键 Id 索引树, 拿到需要的**需要的全部**, 并放到 sort_buffer 内存块中: **`这里的字段可以控制(rowid 排序)`**
     2. 当 sort_buffer 快要满时, **就对 sort_buffer 中的数据排序**, 排完后, 把数据临时放到磁盘一个小文件中
     3. 继续回到主键 id 索引树取数据, 继续放到 sort_buffer 内存中, 排序后, 也把这些数据写入到磁盘临时小文件中
     4. 继续循环, 直到取出所有满足条件的数据
     5. 最后把磁盘的临时排好序的小文件, 合并成一个有序的大文件: 归并排序算法

   - 既然 sort_buffer 放不下, 就需要用到临时磁盘文件{影响排序效率}: 只放排序相关的 age 字段进 bubffer, 不相关的字段（name, city）==> `rowid 排序`

4. Rowid 排序: 内存放 rowid 与排序字段{`排序的字段+主键id`}, 排序后, 再从库中找数据, 拼接返回

   - max_length_for_sort_data: 默认 1024 字节(1k), 需要的字段占用字节数的和 <= 1024 就不会启用 rowid 排序{**因为 mysql 认为数据不大, 却可以减少回表**}

     - **`使用的是字段的定义最大长度, 而不是实际存储的长度`**
       ![avatar](/static/image/db/mysql-key-orderby-optra-rowid.png)

   - sql flow

     1. MySQL 为对应的线程初始化 sort_buffer, 放入需要排序的 age 字段, 以及主键 id
     2. 从索引树 idx_city, 找到第一个满足 city='深圳' 条件的主键 id, 也就是图中的 id=9
     3. 到主键 id 索引树拿到 id=9 的这一行数据, **取 age 和主键 id 的值**, 存到 sort_buffer
     4. 从索引树 idx_city 拿到下一个记录的主键 id, 即图中的 id=13
     5. 重复步骤 3、4 直到 city 的值不等于深圳为止
     6. 前面 5 步已经查找到了所有 city 为深圳的数据, 在 sort_buffer 中, 将**所有数据根据 age 进行排序**
     7. 遍历排序结果, 取前 10 行, 并按照 id 的值回到原表中, 取出 city、name 和 age 三个字段返回给客户端

     ![avatar](/static/image/db/mysql-key-orderby-rowid.png)

5. 全字段排序 vs rowid 排序: max_length_for_sort_data

   - 全字段排序: sort_buffer 内存不够的话, 就需要用到**磁盘临时文件**, 造成磁盘访问
   - rowid 排序: sort_buffer 可以放更多数据, 但是需要再回到原表去取数据, 比全字段排序**多一次回表**

6. 倒排

   - 数据页页中有一块空间叫"槽": **槽中存放着每个分组内最后一条记录在页面中的地址偏移量**

7. 5.6 之后, 排序字段来自不同表的话, **会将关联结果保存到临时表中**: using temporary;using filesort
8. 5.6 之后, 针对 order by limit 做了个小优化:

   - **排序字段无索引且列值不唯一时**: 优化器在遇到 order by limit 语句的时候使用了 priority queue

9. 优化建议

   - sort_buffer_size + max_length_for_sort_data
   - 无 where 基本上都不走索引{**mysql 认为全表的回表代价大**}: limit || 加条件
   - limit 大页问题
   - in 多个值会导致断层的索引失效{1 个不会}: 可以拆开写 SQL 之后再~~归并~~排序
   - 联合索引{正排倒排} + 覆盖索引: 索引存储顺序与 order by 不一致

     ```sql
     alter table staff add  index idx_city_age(city,age);

     -- sql flow
     -- 1. 从索引idx_city_age找到满足city='深圳’ 的主键 id
     -- 2. 到主键 id索引取出整行, 拿到 name、city、age 三个字段的值, 作为结果集的一部分直接返回
     -- 3. 从索引idx_city_age取下一个记录主键id
     -- 4. 重复步骤 2、3, 直到查到第10条记录, 或者是不满足city='深圳' 条件时循环结束
     ```

     ![avatar](/static/image/db/mysql-key-orderby-opt-flowr.png)

### group by

### join

1. 子查询
2. join 原理: a join b --> join c

   - left join: 如果可以命中索引, 就会先使用 索引 过滤一下数据, 之后才会进行 join;
   - left join: 如果没有则会先做 join 之后根据 where 对 join 之后的结果进行过滤

3. 关联的算法是 Nest Loop Join:

   - 是通过驱动表的结果集作为循环基础数据, 然后一条一条地通过该结果集中的数据作为过滤条件到下一个表中查询数据, 然后合并结果
   - 如果还有第三个参与 Join, 则再通过前两个表的 Join 结果集作为循环基础数据, 再一次通过循环查询条件到第三个表中查询数据, 如此往复
   - 所以, 小表驱动大表所建立的连接次数也远比大表驱动小表所建立的连接次数要小的多 + **被被驱动表上简历索引**
   - inner join mysql 会自动优化大小表的顺序
   - 多关联一个表, 就会多分配一个关联缓存(join_buffer_size): 如果在一个 SQL 中关联的表越多, 所占用的内存也就越大
   - join_buffer_size 参数不合理: 容易造成服务器内存溢出的情况, 影响数据库性能的稳定性

4. 小表在前的原理:

   - 最终产生的 row 不会变化, 但是过程中时不一样的 cost
   - 左表就一条记录, join 右表则是顺序读

5. a left join b ?? b left join a

   - 如果 where 条件中含有 table_b 的非空条件[除开 is null] 会被优化成笛卡尔积的 join, 否则按照 SQL 执行
   - 优化器回去比较这两种的 cost: `scan a' cost[io+cpu] + a's rows[某个地方记录的近似值] * b's cost`

6. calculate a's cost between all-scan and index: io+cpu

   - 全表扫描的 cost: rows \* 读取一行的 cost + 顺序读
   - 走索引的 cost: 走索引的 cost 会默认认为回表 索引, 扫描该索引的 cost + 索引过滤后的行数 \* 回表时读取一行的 cost + 随机读

7. table_a has index of idx_a and idx_b, how to choose index

   - idx_a's cost: 扫描 idx_a 的 cost + idx_a 过滤后的行数 \* 回表时读取一行的 cost
   - idx_b's cost: 扫描 idx_b 的 cost + idx_b 过滤后的行数 \* 回表时读取一行的 cost
