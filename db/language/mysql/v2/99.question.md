### 1. null 对 mysql 性能影响

1. 数据列[索引列]尽量不要有 null[非索引列无所谓], 最好都设置有默认值
   - 存储大量的 null 值, 除了计算更复杂之外, 数据扫描的代价也会更高一些
2. 辅助索引需要 mvcc 多版本读的时候，为什么需要依赖聚集索引
   - 辅助索引中不存储 db_trx_id, 需要依托聚集索引实现 mvcc
3. 索引列允许为 null, 会额外存储更多字节码
   - 定义列值允许为 null 并不会增加物理存储代价, 但对索引效率的影响要另外考虑
4. 叶子节点总是存储最新数据, 而非叶子节点则不一定
5. avg/sum(null) 统计一个只有 null 值的列 值为 null
6. null=null 的结果是 null; null!=null 的结果也是 null
   - 需要使用 is [not] null
7. is null 是一直会失效的; is not null 在非覆盖索引下会失效, 覆盖索引下不会失效

### 2. mysql 的数据隔离级别从可重复读改为读已提交的影响是什么: 我们项目就是这么改的{阿里云默认级别}

1. 为什么要改?
2. 之前的需要可重复读的场景怎么解决: 比如对账业务
3. 举例说明对高并发秒杀的影响

### 3. insert into 只会锁主键索引树[行锁-与隔离级别无关]

1. 成功加的是行写锁: 本 session 无限制, 其他 session 此时想获取表写读锁是阻塞, 获取该行的读锁阻塞

   - **会在 insert 的行对应的索引记录上加一个排它锁**
   - 没有 ga: 所以并不会阻塞其他 session 在 gap 间隙里插入记录
   - 在 insert 操作之前会加意向的 gap 锁: **为了提高数据插入的并发能力**
     1. 预示着当多事务并发插入相同的 gap 空隙时, 只要插入的记录不是 gap 间隙中的相同位置, 则无需等待其他 session 就可完成, 这样就使得 insert 操作无须加真正的 gap lock
     2. 假设有一个记录索引包含键值 4 和 7, 不同的事务分别插入 5 和 6, 每个事务都会产生一个加在 4-7 之间的插入意向锁, 获取在插入行上的排它锁, 但是不会被互相锁住, 因为数据行并不冲突

2. **其他唯一索引列引起的失败则重复的索引记录上加读锁: 本/其他 session 无限制** + **插入引起的死锁**
3. _失败会在重复的索引记录上加读锁: 本 session 无限制, 其他 session 此时想获取表写读锁是阻塞, 获取该行的读锁阻塞_

### 4.数据太多: 分库分表

1. 数据量的衡量
2. 垂直分区: 指数据表列的拆分, 把⼀张列⽐较多的表拆分为多张表

   - 减少 I/O 次数, 垂直分区可以简化表的结构,易于维护
   - 主键会出现冗余, 引起 Join 操作[在应⽤层进⾏ Join], 让事务变得更加复杂；

3. ⽔平分区: ~~表结构不变, 每⼀⽚数据分散到不同的库中~~ Sharding-JDBC

   - ⽀持⾮常⼤的数据量存储, 应⽤端改造也少, 但 分⽚事务难以解决
   - 跨节点 Join 性能差, 逻辑复杂

### 5. SQL 查询流程

1. Client
2. Connectors
3. ~~Cache~~

   - 缓存失效时针对表的, 不建议使用
   - sql_no_cache/sql_cache

4. Parser: 让 MySQL 知道做什么

   - `select SQL_CACHE * from T where ID=10;`
   - 词法分析: MySQL 从你输入的 "select" 这个关键字识别出来, 这是一个查询语, 它也要把字符串 T 识别成表名 T , 把字符串 ID 识别成 列 ID
   - 语法分析: 是否满足 MySQL 语法

5. Optimizer: MySQL 决定怎么做

   - 优化器是在表里面有多个索引的时候, 决定使用哪个索引;
   - 或者在一个语句有多表关联的时候, 决定各个表的连接顺序
   - ...

6. Executor: 做事情

   - 判断有无表操作的权限
   - 打开表执行器会根据表的引擎定义, 去使用这个引擎提供的接口获取数据
   - 比如 `4` 的 SQL 且 ID 字段没有索引, 执行器的执行流程
     1. 调用 InnoDB 引擎接口取这个表的第一行, 判断 ID 值是不是 10, 如果不是则跳过, 如果是则将这行存在结果集中;
     2. 调用引擎接口取下一行 , 重复相同的判断逻辑, 直到取到这个表的最后一行
     3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端

   ![avatar](/static/image/db/mysql-sql-execute-flow.png)

#### 5-1.非聚簇索引的查询过程

```sql
create table T (
   ID int primary key,
   k int NOT NULL DEFAULT 0,
   s varchar(16) NOT NULL DEFAULT '',
   index k(k)
) engine=InnoDB;

insert into T values(100, 1,  'aa'), (200, 2, 'bb'), (300, 3, 'cc'), (500, 5, 'ee'), (600, 6, 'ff'), (700, 7, 'gg');

-- execute flow
select * from T where k between 3 and 5
```

1. 在 k 索引树上找到 k=3 的记录, 取得 ID = 300
2. 再到 ID 索引树查到 ID=300 对应的 R3
3. 在 k 索引树取下一个值 k=5 , 取得 ID=500
4. 再回到 ID 索引树查到 ID=500 对应的 R4
5. 在 k 索引树取下一个值 k=6 , 不满足条件, 循环结束.

   ![avatar](/static/image/db/mysql-index-query.png)

6. `select ID from T where k between 3 and 5`:

   - 在引擎内部使用覆盖索引在索引 k 上其实读了三个记录
   - R3~R5[对应的索引 k 上的记录项], 但是对于 MySQL 的 Server 层来说, 它就是找引擎拿到了两条记录, 因此 MySQL 认为扫描行数是 2

### 6. SQL 更新流程

1. Client
2. Connectors
3. ~~Cache~~: 使该表的缓存全部失效
4. Parser: 分析器会通过词法和语法解析知道这是一条更新语句
5. Optimizer: 优化器决定要使用 ID 这个索引
6. Executor: 执行器负责具体执行, 找到这一行, 然后更新
7. Engines:

   - 执行器先`找引擎取` ID=2 这一行: ID 是主键, 引擎直接用树搜索找到这一行, 如果 ID=2 这一行所在的数据页本来就在内存中, 就直接`返回给执行器`; 否则, 需要先从磁盘读入内存, 然后再返回
   - `执行器`拿到引擎给的行数据, 把这个值`加上 1`, 比如原来是 N , 现在就是 N+1 , 得到新的一行数据, 再`调用引擎接口写入这行新数据`
   - `引擎`将这行新数据`更新到内存`中, 同时将这个更新操作`记录到 redo log 里面`, 此时 **redo log 处于 prepare 状态**, ~~然后`告知执行器执行完成了`, 随时可以提交事务~~
   - **执行器生成这个操作的 binlog , 并把 binlog 写入磁盘**: 此时可以告诉执行引擎事务完成
   - **执行器调用引擎的提交事务接口, 引擎把刚刚写入的 redo log 改成提交 commit 状态, 更新完成**

8. crash-safe: redolog+ binlog

   - 如果客户端收到事务成功的消息, 事务就一定持久化了
   - 如果客户端收到事务失败[比如主键冲突、回滚等]的消息, 事务就一定失败了
   - 如果客户端收到 "执行异常"的消息, 应用需要重连后通过查询当前状态来继续后续的逻辑
     - **此时数据库只需要保证[数据和日志之间, 主库和备库之间]一致就可以了**

9. 与查询流程不一样的是, 更新流程还涉及两个重要的日志模块: `redo log 和 binlog`
10. `简单说, redo log 和 binlog 都可以用于表示事务的提交状态, 而两阶段提交就是让这两个状态保持逻辑上的一致`

![avatar](/static/image/db/mysql-update-flow.png)

### 7. redo-log 日志需要两阶段提交

1. 存储引擎更新数据时会更新内存数据且写 redo log, 并设置为 prepare 阶段
2. 之后会告诉执行器, 执行完成, 执行器会写 bin-log
3. 之后执行器会调用存储引擎**提交事务**接口, 引擎把刚刚写入的 redo log 改成提交 commit 状态
4. 此时更新操作就算结束, 后续会将 redo log 的内容持久化的磁盘

5. why?

   - 由于 redo log 和 binlog 是两个独立的逻辑
   - `先写 redo log 后写 binlog`: 假设在 redo log 写完, binlog 还没有写完的时候, MySQL 进程异常重启. 由于我们前面说过的, redo log 写完之后, 系统即使崩溃, 仍然能够把数据恢复回来, 所以恢复后这一行的值是 1 . 但是由于 binlog 没写完就 crash 了, 这时候 binlog 里面就没有记录这个语句. 因此, 之后备日志的时候, 存起来的 binlog 里面就没有这条语句. 然后你会发现, 如果需要用这个 binlog 来恢复临时库的话, 由于这个语句的 binlog 丢失, 这个临时库就会少了这一次更新, 恢复出来的这一行 c 的值就是 0 , 与原库的值不同.
   - `先写 binlog 后写 redo log`: 如果在 binlog 写完之后 crash, 由于 redo log 还没写, 崩溃恢复以后这个事务无效, 所以这一行 c 的值是 0. 但是 binlog 里面已经记录了 _把 c 从 0 改成 1_ 这个日志. 所以, 在之后用 binlog 来恢复的时候就多了一个事务出来, 恢复出来的这一行 c 的值就是 1 , 与原库的值不同.

### 8. MySQL IO 相关瓶颈性能优化: 双一 + 组提交

1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数

   - 减少 binlog 的写盘次数
   - 可能会增加语句的响应时间, 但没有丢失数据的风险

2. 将 sync_binlog 设置为大于 1 的值[比较常见是 100~1000]

   - 风险: 主机宕机时会丢 binlog 日志且不能回滚事务{主备不一致}

3. 将 innodb_flush_log_at_trx_commit 设置为 2

   - 风险: 主机宕机时会丢数据

### 9.非双一设置场景

1. 业务高峰期: 一般如果有预知的高峰期, DBA 会有预案, 把主库设置成非双 1
2. 备库延迟, 为了让备库尽快赶上主库
3. 用备份恢复主库的副本, 应用 binlog 的过程, 这个跟上一种场景类似
4. 批量导入数据的时候
5. 一般情况下, 把生产库改成非双 1 配置
   - innodb_flush_logs_at_trx_commit=2
   - sync_binlog=1000

### 10. 恢复到指定的时刻的数据

1. 找到最近的一次全量备份, 从这个备份恢复到临时库
2. 从备份的时间点开始, 将备份的 binlog 依次取出来, 重放到指定时刻

### 12. 索引分析案例

```sql
CREATE TABLE `geek` (
   `a` int(11) NOT NULL,
   `b` int(11) NOT NULL,
   `c` int(11) NOT NULL,
   `d` int(11) NOT NULL,
   PRIMARY KEY (`a`,`b`),
   KEY `c` (`c`),
  -- KEY `ca` (`c`,`a`),
   KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
```

1. 由于历史原因, 这个表需要 a, b 做联合主键, 所以 `index(a, b)`
2. ~~所以 `index(c, a)` for `select * from geek where c=N order by a limit 1;`?~~： this is no use.
3. 所以 `index(c, b)` for `select * from geek where c=N order by b limit 1;`?
4. 分析索引

   - `index(a, b)`:

     |  a  |  b  |  c  |  d  |
     | :-: | :-: | :-: | :-: |
     |  1  |  2  |  3  |  d  |
     |  1  |  3  |  2  |  d  |
     |  1  |  4  |  3  |  d  |
     |  2  |  1  |  3  |  d  |
     |  2  |  2  |  2  |  d  |
     |  2  |  3  |  4  |  d  |

   - `index(c)`: `same as index(c, a)` - **ab 是主键**

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  1  |  3  |
     |  2  |  2  |  2  |
     |  3  |  1  |  2  |
     |  3  |  1  |  4  |
     |  3  |  2  |  1  |
     |  4  |  2  |  3  |

   - ~~`index(c, a)`~~: `same as index(c)`

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  1  |  3  |
     |  2  |  2  |  2  |
     |  3  |  1  |  2  |
     |  3  |  1  |  4  |
     |  3  |  2  |  1  |
     |  4  |  2  |  3  |

   - `index(c, b)`

     |  c  |  a  |  b  |
     | :-: | :-: | :-: |
     |  2  |  2  |  2  |
     |  2  |  3  |  1  |
     |  3  |  1  |  2  |
     |  3  |  2  |  1  |
     |  3  |  4  |  1  |
     |  4  |  3  |  2  |

### 13.数据库的备份

1. 使用**全局锁**, 保证拿到的数据是一致的: FTWRL
   - 课程和账户金额的反证法
2. innodb 可以 `mysqldump –single-transaction` 开启事务然后保证数据的一致性
3. `set global readonly=true` 不好
   - readonly 的值会被用来做其他逻辑{判断是否是主库}
   - 异常处理机制上有差异: FTWRL 在客户端异常断开连接时会自动释放这个全局锁, readonly 不会{长时间不可写}

### 14.唯一索引影响并发

1. [link](./06.index.md): change buffer
2. 如果我们能在业务意义上保证某个字段是唯一的, 并且这张表又是一个经常写入数据的表, 那么这里 moon 推荐你用普通索引, 而不是唯一索引, 原因如下:
   - 在读取数据的时候, 普通索引在查到满足第一个条件的记录后, 会继续查找下一个记录, 直到第一个不满足条件的记录,
   - 而唯一索引, 查找到第一个满足条件的记录时, 就直接停止了
   - 这样看来其实唯一索引更好, 但是实际观察来看, 这种性能的差异微乎其微, 况且我们还可以在查询语句上用 limit 1 来限制: **数据是按照页读取的**
   - 在更新过程中, 普通索引的更新因为不用考虑唯一性, 会将这次更新操作直接写入 change buffer 中, 之后会定期或者再次访问到这个数据页的时候持久化到磁盘当中
   - 而唯一索引的更新不能用 change bufer, 原因是要在表中判断是否已经有该条记录, 所以会有一个将数据页读入内存的 IO 操作, 而 IO 操作又是很消耗资源的
3. 产生死锁

   ![avatar](/static/image/db/mysql-lock-unique-deadlock.png)

### 16.删除数据的过程

1. 查找过程
2. 标记删除

   - InnoDB 引擎只会把该记录标记为删除
   - 如果之后要再插入一个 ID 在之间的记录时, 可能会复用这个位置{**记录的复用**}
   - 但是磁盘文件的大小并不会缩小

3. 如果我们删掉了一个数据页上的所有记录则该**数据页可以复用**
4. 如果相邻的两个数据页利用率都很小, 系统就会把这两个页上的数据合到其中一个页上, 另外一个数据页就被标记为可复用
5. 如果用 delete 命令把整个表的数据删除, 则所有的数据页都会被标记为可复用, 但是磁盘上, 文件不会变小
6. 空洞: 这些可以复用而没有被使用的空间{删除插入都会造成空洞}
7. 经过大量增删改的表, 都是可能是存在空洞的, 所以如果能够把这些空洞去掉, 就能达到收缩表空间的目的

   - **重建表: `alter table t engine=InnoDB,~~ALGORITHM=inplace~~;`** +`不建议在线上环境使用{可以使用gh-ost}`
   - alter 语句在启动的时候需要获取 MDL 写锁
   - 在真正拷贝数据之前就退化成读锁: 为了实现 Online, MDL 读锁不会阻塞增删改操作 + 禁止其他线程对这个表同时做 DDL
   - `alter table t add FULLTEXT(field_name);`: 这个是会 block 的
   - DDL 过程如果是 Online 的, 就一定是 inplace 的; 反过来就不一定了
   - 在重建表的时候, InnoDB 不会把整张表占满, 每个页留了 1/16 给后续的更新用

   ![avatar](/static/image/db/mysql-recreate-flow.png)

8. 重建表的流程

   - 建立一个临时文件, 扫描表 A 主键的所有数据页
   - 用数据页中表 A 的记录生成 B+树, 存储到临时文件中**{5.6 之后 innodb 内}+ 需要空间**
   - **生成临时文件的过程中, 将所有对 A 的操作记录在一个日志文件[row log]中, 对应的是图中 state2 的状态**
   - 临时文件生成后, 将日志文件中的操作应用到临时文件, 得到一个逻辑数据上与表 A 相同的数据文件, 对应的就是图中 state3 的状态
   - 用临时文件替换表 A 的数据文件

9. 重建表的方式
   - alter table t engine = InnoDB: 关注点在数据页{空间}
   - analyze table t: 重现统计索引信息, 不修改数据
   - optimize table t: `recreate + analyze`

### 17.内存刷脏页: redolog / change bugger

1. 当内存数据页跟磁盘数据页内容不一致的时候, 我们称这个**内存页为 "脏页"**: change buffer
2. 内存数据写入到磁盘后, 内存和磁盘上的数据页的内容就一致了, 称为"干净页"
3. flush 时机

   - InnoDB 的 redo log 写满: **系统会停止所有更新操作**, 把 checkpoint 往前推进, redo log 留出空间可以继续写
   - 系统内存不足: 当需要新的内存页且内存不够用的时候, 就要淘汰一些数据页, 如果淘汰的是 "脏页", 就要将脏页写到磁盘
     1. 一个查询要淘汰的脏页个数太多, 会导致查询的响应时间明显变长
   - 系统空闲的时候:
   - MySQL 正常关闭: 内存的脏页都 flush 到磁盘上

4. innodb_io_capacity: 主机的 IO 能力{InnoDB 全力刷脏页时速度}

   - 建议: `磁盘的IOPS`
   - `fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest`

5. 脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total
6. MySQL 刷脏页, 如果发现旁边的数据页刚好是脏页会一起刷掉{蔓延}: `innodb_flush_neighbors`
7. 设计策略控制刷脏页的速度
   - 脏页比例: `innodb_max_dirty_pages_pct{0.75}`
   - redo log 写盘速度

### 18.`count(*) 问题`

1. 为什么不直接记录一下总数呢

   - 因为即使是在同一个时刻的多个查询, 由于 MVCC 的原因, InnoDB 表返回行数是不确定的{事务设计有关}
   - 每一行对当前事务是否可见都是不一定的

2. MySQL 优化器会找到最小的那棵树来遍历

   - 在保证逻辑正确的前提下, **尽量减少扫描的数据量**, 是数据库系统设计的通用法则之一

3. `count(*)`

   - MyISAM 表虽然 count(\*)很快, 但是不支持事务{没有 where 时}
   - show table status 命令虽然返回很快, 但是不准确
   - InnoDB 表直接 count(\*) 会遍历全表, 虽然结果准确, 但会导致性能问题

4. 解决办法: {自己记下来}

   - 用缓存系统保存计数: 缓存可能丢失{重启时执行一次 count(\*)} + 逻辑上不精确的{获取总数和获取记录不是原子的}
   - 在数据库保存计数: 单独的一张计数表 C{不会丢失} + 一个事务内是 RR, 所以是精确的

5. count 性能问题

   - server 层要什么就给什么
   - InnoDB 只给必要的值
   - 现在的优化器只优化了 count(\*)的语义为 "取行数"
   - `count(字段)<count(主键id)<count(1)≈count(*)`

6. `count(*)` 执行流程

### 19.rand(): 随机下的性能

- sort_buffer_size

```sql
-- 1w rows
explain select word from t_words order by rand() limit 3; {Using temporary; Using filesort}
```

1. order by rand() 执行过程: 扫描行数很多有性能有问题的

   - 创建一个临时表{内存/磁盘}: memory 引擎的{**tmp_table_size** 值大于会被放入的值}, R(), W{字段长度}
   - 从 words 表中, 按主键顺序取出所有的 word 值, 插入临时表, **扫描 1w 行**
   - 现在临时表有 10000 行数据, 按照字段 R 排序
   - 初始化 sort_buffer{double 类型, 整型}: sort_buffer_size 会影响排序算法{归并排序算法[临时文件], 优先队列排序算法}
   - 临时表中一行一行地取出 R 值和位置信息存入 sort_buffer[对内存临时表做全表扫描], **扫描 +1w 行**
   - 在 sort_buffer 中根据 R 的值进行排序
   - 排序完成后, 取出前三个结果的位置信息, 依次到内存临时表中取出 word 值, 返回给客户端, **扫描 +3 行**
   - 这个过程中, 总扫描行数变成了 20003

   ![avatar](/static/image/db/mysql-random.png)

2. **order by rand()使用了内存临时表, 内存临时表排序的时候使用了 rowid 排序方法{优先队列排序算法}**

   - 内存临时表: 这个适合参数 tmp_table_size 有关
   - rowid: 这个是因为内存临时表, 不会回表问题
   - 优先队列排序算法: sort_buffer_size 大于 limit{真实需要的字段大小{这里就是 rowid+R} \* limit}

3. 随机排序方法

   - `M=max(id), N=min(id), X = (M-N)*rand() + N` + 取不小于 X 的第一个 ID 的行

     1. 这个会使用索引, 不会大量扫描数据
     2. 但是并不是真正的随机
     3. code

     ```sql
     select max(id),min(id) into @M,@N from t ;
     set @X= floor((@M-@N+1)*rand() + @N);
     select * from t where id >= @X limit 1;
     ```

   - **`C=count(*) + Y = floor(C * rand()) + limit Y,1`**
     1. 一共会扫描 C+Y+1 行: count(\*) 扫描 C 行 + `limit Y,1` 会扫描 Y+1 行
     2. 但是由于是 id primary, 代价比 order by random() 小很多
     ```sql
     -- select * from t limit count(*)*rand() 1;
     mysql>
        select count(*) into @C from t;
        set @Y1 = floor(@C * rand());
        set @Y2 = floor(@C * rand());
        set @Y3 = floor(@C * rand());
        select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
        select * from t limit @Y2，1；
        select * from t limit @Y3，1；
     ```

### 20.CPU 一直 100%

1. show processlist: 有一个一直再执行, 临时表一直在创建, CPU 一直很高
2. kill 不掉{只发出指令}, 是个 bug 就直接重启数据库

   ```sql
   show processlist ;
   select  * from information_schema.INNODB_TRX;
   kill query  263607;

   show global status like '%created_tmp%';
   show variables like '%table_size%';
   ```

### 21.存在就更新不存在就插入

1. `insert … on duplicate key update`
2. 在高并发下会产生死锁

   ![avatar](/static/image/db/mysql-deadlock.png)

### 22.频繁 CRUD 为什么嘛会导致索引失效

1. 频繁的 CRUD 会导致索引页空洞[索引时有序的]
2. 造成索引页空洞影响索引区分度
   - 索引基数, 即索引的区分度计数是抽样基数
   - MySQL 会随机抽取几个数据页, 计算这些数据页上不同数据的个数, 并取平均值乘上总页数, 得到索引的区分度
   - 页空洞会造成索引的区分度变小[页数大但是有效数据少], 会影响优化器的预计扫描行数
3. 索引区分度会索引分析时的计数[影响索引计数]
4. 影响索引基数 => 优化器判断索引消耗的多 => 选错索引=索引失效
   - 优化器选择索引, 会主要根据扫描行数进行判断
   - 对于普通索引, 如果查询的数据要回表, 扫描行数和回表的消耗是绑定的, 就会出现以下情况
5. test: id(ai), a(index), b, RR
   - 插入 10w 数据, a[1-10w]
   - session A: 开启事务, 锁住之前这批数据
   - session B: 开启事务, 删除这批数据, 再次插入 10w 数据 a[1-10w], 此时查询 1w<a<2w explain 时有 3w 行[即使 a 是 unique-index]
6. 解决方法
   - [recreate] alter table t engine = InnoDB
   - [analyze] analyze table t 其实不是重建表, 只是对表的索引信息做重新统计, 没有修改数据, MDL 读锁
   - optimize table t 等于 recreate+analyze

### 23.重建索引

1. 索引可能因为删除, 或者页分裂等原因, 导致数据页有空洞
2. 重建索引的过程会创建一个新的索引, 把数据按顺序插入, 这样页面的利用率最高, 也就是索引更紧凑、更省空间
3. 方式
   - analyze table t: 重现统计索引信息, 不修改数据
   - optimize table t: `recreate + analyze`

### 25.性能问题

1. 连接问题

   - 数据库建立连接需要三次握手{网络} + 和 SERVER 的权限校验, 是一个很消耗资源的事情, 所以一般都会池化
   - 连接数过多
     1. 可以 show processlist + `information_schema.innodb_trx` 删除一些 sleep 的连接
     2. 排查代码看看为什么消耗连接: 假批量操作
     3. 减少连接过程的消耗: 去掉权限校验{默认就会只能本地连接}

2. 代码问题

   - 索引没有设计好: 紧急创建索引 + 创建索引都支持 Online DDL
   - SQL 语句没写好: **query_rewrite**/ 相关服务下线

     ```sql
     insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");
     call query_rewrite.flush_rewrite_rules();
     ```

   - MySQL 选错了索引: `加上force index`

3. 如果避免
   - 测试环境查看慢查询: **Rows_examined**
   - 测试环境压测
   - 测试环境模拟数据测试
   - **pt-query-digest 审计**

### 26.长事务问题

1. undolog 日志越来越大: 长事务意味着系统里面会存在很老的事务视图

   - 由于这些事务随时可能访问数据库里面的任何数据, 所以这个事务提交之前
   - 数据库里面它可能用到回滚记录都必须保留, 这就会导致大量占用存储空间

   ![avatar](/static/image/db/mysql-slow-undolog.png)

2. 并发情况下, 数据库连接池容易被撑爆
3. 容易造成大量的阻塞和锁超时
   - 长事务还占用锁资源, 也可能拖垮整个库
4. 执行时间长，容易造成主从延迟
5. 回滚所需要的时间比较长
6. MySQL 5.5 之前回滚日志是跟数据字典一起放在 ibdata 文件里的, 会导致其很大很大

### 27.将 RR 改为 RC 的原因

1. mysql 默认使用 RR 的原因: 幻读 + SM 早期问题 + 使用场景(不多的, **其他数据库都不是**)
2. 区别-rr & rc 对 crud 的影响

   ![avatar](/static/image/db/mysql-rr-rc.png)

3. 区别-影响: 脏读 不可重复度 幻读

   - 改成 RC 后的幻读问题需要自己解决: 很多时候幻读问题其实是可以忽略的, 或者可以用其他手段解决

4. 区别-一致性读: 使用快照信息显示基于某个时间点的查询结果, 而**不考虑与此同时运行的其他事务所执行的更改**

   - 只有 RC 和 RR 才会使用一致性读: mvcc 实现的
   - RC 每次读取都会重新生成一个快照, **总是读取行的最新版本**
   - RR 的快照是在事务开始时生成, **只有在本事务中对数据进行更改才会更新快照**

   - RC 还支持 `半一致读`: 一条 update 语句, 如果 where 条件匹配到的记录已经加锁, 那么 InnoDB 会返回记录最近提交的版本, 由 MySQL 上层判断此是否需要真的加锁

5. 区别-锁机制

   - RC 只会对索引增加 Record Lock, 不会添加 Gap Lock 和 Next-Key Lock
   - RR 为了解决幻读的问题, 在支持 Record Lock 的同时, 还支持 Gap Lock 和 Next-Key Lock
   - **RR 更加容易产生死锁**: 间隙锁对插入的影响{RC 下没有间隙锁}

6. 区别-主从同步

   - RC 隔离级别只支持 row 格式的 binlog
   - 如果指定了 mixed 作为 binlog 格式, 那么如果使用 RC, 服务器会自动使用基于 row 格式的日志记录
   - RR 的隔离级别同时支持 statement{有问题一般不用}、row 以及 mixed 三种

7. 为什么改成 RC

   - 提升并发: RC 的锁小 + 半一致读
   - 减少死锁: RC 的锁小

8. https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650123710&idx=1&sn=4601abda3d87a7d8651db8c6511a47f9&chksm=f36bb09fc41c3989e4eb6a6674279707328a0cdeebcc67e6c2138137530f0c8c446f75a403eb&scene=21#wechat_redirect

### 27. mysql 默认使用 RR 的原因

1. 好处: next-key lock 能解决幻读问题
2. 解决主从同步且在 statement's bin-log 下的主从一致问题

   - MySQL 早期只有 statement 这种 bin log 格式: bin log 记录的是 SQL 语句的原文
   - **当出现事务乱序的时候, 就会导致备库在 SQL 回放之后, 结果和主库内容不一致**
   - 为了解决这个问题, MySQL 默认采用了 RR 隔离级别: 在 RR 中, 会在更新数据的时候增加记录锁的同时增加间隙锁

### 27.可重复读的场景

1. 假设你在管理一个个人银行账户表, 一个表存了每个月月底的余额, 一个表存了账单明细
2. 这时候你要做数据校对, 也就是判断上个月的余额和当前余额的差额, 是否与本月的账单明细一致
3. 你一定希望在校对过程中, 即使有用户发生了一笔新的交易, 也不影响你的校对结果
4. 这时候使用 可重复读 隔离级别就很方便
5. **可以单独设置某个 session 的隔离级别**

### 28. RC vs RR 之无索引下的 lock

1. pre env

   ```sql
   create table `yes` (
      `id` bigint(20) not null auto_increment,
      `name` varchar(45) default null,
      `address` varchar(45) default null,
      primary key (`id`)
   ) engine=innodb default charset=utf8mb4

   insert into tools.yes (id, name, address) values (4, 'yes', 'hz');
   insert into tools.yes (id, name, address) values (5, 'xx', 'hz');
   insert into tools.yes (id, name, address) values (6, 'aa', 'sh');

   -- 查看锁
   select * from information_schema.innodb_lock_waits ;
   select * from information_schema.innodb_locks;
   select * from information_schema.innodb_trx;
   ```

2. rc: **没有索引** + **在读提交级别下, 锁的只是已经存在的记录**

   - 锁定的列为非索引列, 加锁都是加到主键索引上的: {导致全表扫描式的加锁}
   - [行锁(不是表锁)-锁了符合条件的行]~~update/for update: 先找到满足**条件**的, 看上面时会否有**锁**, 有则阻塞, 无则加锁并更新~~
   - select..for update 表现出来的结果是**扫描到的记录先加锁，再判断条件，不符合就立马释放，不需要等到事务提交**; 而 update 的扫描是先判断是否符合条件, 符合了才上锁
   - 可以 insert

   ```sql
   -- session 01: this will lock primary id 5 -- 最终只有 id=5的锁
   select * from yes where name='xx' for update

   -- session 02: 此时可以insert
   select * from yes where name='yes' for update;      --  blocked, 此时遍历到id=5时阻塞
   update yes set address='gz' where name='yes'        --  no blocked, 查找到name=yes记录的id=4, 发现没有锁, 可以加锁更新
   update yes set address='gz' where name='xx'         --  blocked
   ```

3. RR 下: **没有索引** + 锁全部行

   - 锁定的列为非索引列, 加锁都是加到主键索引上的
   - update/for update: 从前往后全表扫描的顺序, 遍历的记录**先上锁**, 上锁之后发现不满足**条件**, 则不会释放锁
   - 不可以 insert

   ```sql
   -- session 01: this will lock primary id 4 -- 此时会全部锁住
   select * from yes where name='xx' for update

   -- session 02: 此时不可以insert
   select * from yes where name='yes' for update;   --  blocked
   update yes set address='gz' where name='xx'      --  blocked, 遍历加锁, 发现 id=4 上有锁阻塞
   update yes set address='gz' where name='yes'     --  blocked
   ```

### 29. RC vs RR 之索引下的 lock

1. pre env

   ```sql
   create table `yes` (
      `id` bigint(20) not null auto_increment,
      `name` varchar(45) default null,
      `address` varchar(45) default null,
      primary key (`id`),
      KEY `idx_name` (`name`)
   ) engine=innodb default charset=utf8mb4

   insert into tools.yes (id, name, address) values (4, 'yes', 'hz');
   insert into tools.yes (id, name, address) values (5, 'xx', 'hz');
   insert into tools.yes (id, name, address) values (6, 'aa', 'sh');

   -- 查看锁
   select * from information_schema.innodb_lock_waits ;
   select * from information_schema.innodb_locks;
   ```

2. rc: **有索引** + 只锁存在的记录

   - 锁定的列为索引列, 加锁都是加到索引列{非聚簇索引}上的
   - 可以 insert
   - **update/for update: 锁记录本身**, 行为一致, **且都是先判断条件后加锁**

   ```sql
   -- session 01: lock idx_name - xx,5
   select * from yes where name='xx' for update

   -- session 02:
   select * from yes where name='yes' for update;      --  no blocked, 先找到后加锁
   update yes set address='gz' where name='yes'        --  no blocked, idx_name 的yes,4 上没有锁, 发现没有锁, 可以加锁更新
   update yes set address='gz' where name='xx'         --  blocked, idx_name 的xx,5 上有锁, 阻塞
   ```

3. RR 下: **有索引** + 只锁存在的记录 + GAP

   - 锁定的列为索引列, 加锁都是加到索引列{非聚簇索引}上的
   - 不可以 insert
   - **update/forupdate: 锁记录本身 + 间隙**, 都是遍历加锁且不释放

   ```sql
   -- session 01: lock  idx_name - (aa, xx)   --- 此时插入 bb 会阻塞, 但是插入 yyy 不会阻塞
   select * from yes where name='xx' for update

   -- session 02: 此时不可以insert
   select * from yes where name='yes' for update;   --  no blocked
   update yes set address='gz' where name='xx'      --  blocked, 遍历加锁, 发现 idx_name xx 上有锁阻塞
   update yes set address='gz' where name='yes'     --  no blocked
   ```

### 30. SQL 语句明明命中了索引, 为什么执行很慢

1. 没命中索引会走全表扫描, 命中了索引也可能走全表扫描

   ```sql
   -- PRIMARY, 但是本质上还是全表扫描
   explain select * from account_member where id>0;
   ```

2. 命中的索引区分度怎么样

   - 当一个表很大时, 不仅要关注是否有索引, 还要关注索引的过滤性是否足够好

3. 查看预计扫描的行数: **core**
4. 命中索引了, 但是是否在回表(**索引下推**) || 排序 || 使用临时表
5. 可能只是当时 CPU 等系统资源过载, 影响到正常 SQL 的执行速度

### 31. MySQL 数据库 cpu 飙升怎么处理

1. 排查过程

   - 使用 top 命令观察, 确定是 mysqld 导致还是其他原因
   - 如果是 mysqld 导致的, show processlist, 查看 session 情况, 确定是不是有消耗资源的 sql 在运行
   - 找出消耗高的 sql, 看看执行计划是否准确, 索引是否缺失, 数据量是否太大

     ```sql
     -- 定位线程
     pidstat -t -p <mysqld_pid> 1  5

     -- performance_schema 这个默认是不开启的: 监控MySQL在一个较低级别的运行过程中的资源消耗/资源等待等情况
     -- https://blog.csdn.net/f746262041/article/details/123548671
     select * from performance_schema.threads where thread_os_id = xx ;
     select * from information_schema.`PROCESSLIST` where  id=`threads.processlist_id`
     ```

     ![avatar](/static/image/db/mysql-opt-cpu.png)

2. 处理

   - kill 掉这些线程(同时观察 cpu 使用率是否下降)
   - 进行相应的调整(比如说加索引、改 sql、改内存参数)
   - 重新跑这些 SQL

3. 其他情况
   - 也有可能是每个 sql 消耗资源并不多, 但是突然之间, 有大量的 session 连进来导致 cpu 飙升
   - 这种情况就需要跟应用一起来分析为何连接数会激增, 再做出相应的调整, 比如说限制连接数等

## 24.delete 与 truncate 的区别

1. 自增 id 问题
2. truncate dml 元数据锁; delete 是 ddl 数据级别的锁
3. 物理空间问题

### 15.简单删除数据空间回收

1. innodb_file_per_table:[5.7,~) 都是开启的
   - OFF: 在系统共享表空间, 跟数据字典在一起{不会删除表结构}
   - ON: 在 `.ibd` 文件中, drop table 会直接删除文件{空间会被回收}

### 34. truncate vs delete vs drop

1. delete: **只删除数据不删除表的结构**

   - innodb 是有事务的: {一条一条删之后再 commit}会先将所删除数据缓存到 rollback segement 中, 事务 commit 之后生效
   - delete 不会保留分区
   - 磁盘空间
     1. delete 全表: myisam 会释放磁盘空间 + innoDB 不会释放
     2. delete 有条件都不释放空间
     3. delete 知道删除多少行
   - innodb 的 delete 不会释放空间: 将数据地址空间标记为可复用, 磁盘文件大小不变{只是把删除的数据行设置为不可见}
   - delete 之后执行 `optimize table table_name` 会释放空间

     ```sql
     -- 查看磁盘占用
     select concat(round(sum(DATA_LENGTH/1024/1024),2),'M') as table_size
     from information_schema.tables
     where table_schema='mc-fb' AND table_name='account_member';
     ```

   - 自增的 ID 不会重置

2. truncate: **只删除数据不删除表的结构**

   - 不走事务: 能够快速清空一个表
   - **直接删除数据文件**, truncate 不知道删除了几条
   - 磁盘空间: **都**立刻释放(把数据文件删除了)
   - truncate 会保留分区
   - 自增 ID
     1. truncate 后**都**会重置为 1
     2. deleteh 会保留 auto_increment 的值: myisam 是记录在表里的, innodb 是在 内存/redolog 中{delete+重启也会重置为 1}

3. drop: 删除数据+表结构

   - 执行后立即生效, 无法回退
   - 立刻释放磁盘空间

### 32. 为什么推荐使用自增 id 作为主键

1. 底层使用的数据结构: b+tree
2. 非聚簇索引的值是主键: 如果该值较大会导致普通索引的存储空间较大
3. 使用自增 id 做主键索引新插入数据只要放在该页的最尾端就可以, 直接按照顺序插入, 不用刻意维护
4. **时间效率:**
   - 向上调整 b+树
   - 寻找插入的位置: 自增则可直接放到尾部, 否则需要查找插入位置
5. 空间效率: **页分裂容易维护**, 当插入数据的当前页快满时, 会发生页分裂的现象, 否则容易发送也分裂
   - 快满: 当达到页面的最大填充因子时候(15k), 流出了 1k 以备修改
   - 页分裂会导致数据磁盘的空洞
6. 缺点
   - 根据数据库的自增 id 获取到你的业务增长信息爬取数据
   - 高并发的负载下自增锁争用: 有一定的性能损失
   - Auto_Increment 锁机制参数 innodb_autoinc_lock_mode
7. 非自增的主要缺点
   - 寻找插入点并将其家载入内存(随机读) + 页分裂(b+树的向上平衡)
   - 磁盘空洞

### 11. 页分裂&合并

1. 页分裂: 如果所在的数据页已经满了, 根据 B+ 树的算法, 这时候需要申请一个新的数据页, ~~然后

   - 性能自然会受影响
   - 页分裂操作还影响数据页的利用率: 原本放在一个页的数据, 现在分到两个页中

2. 当相邻两个页由于删除了数据, 利用率很低之后, 会将数据页做合并
3. 空间问题: `auto_key>random_key>uuid`

### 33. 业务主表读写缓慢如何优化: 冷热分离

1. 并不是所有的问题都是能靠技术解决的: 12306 || 携程{只能查看进一个月的账单}
2. 主表数据太大, 性能问题: 可以考虑冷热分离
3. 冷热分离

   - 在处理数据时将数据库分为热库和冷库两个库
   - 冷库存放的是**走到终态的数据**; 热库存放的是还**需要修改的数据**

4. 冷热分离举例

   - 比如 30 天之内的机票、火车票订单, 用户可能需要对这期间的订单做出退票, 开发票的操作: 因此可以将 30 天之内的订单放到热库中
   - 但是 30 天之前订单却只有查询的需求: 放到冷库中。

5. 什么情况下需要使用冷热分离

   - 主业务响应延迟太大: 比如 12306 下订单太慢了
   - 数据走到终态后: 没有更新需求, 只有读的需求, 比如订单的完成状态
   - **不会同时存在读冷/热数据的需求: 这个是分开的**
   - 用户能够接受新旧数据分开查询: 比如携程的订单查询 30 天之前的需要用手机号查询

6. 热冷数据

   - 热数据: 被频繁更新, 响应时间有要求{核心业务}
   - 冷数据: 不允许更新(具体业务系统具体分析), 偶尔被查询, 响应时间无要求

7. 如何判断一个数据是冷数据(只读)还是热数据(可修改)

   - 根据业务系统区分: 一般而言是根据主表中的一个或者多个字段进行标识区分
   - 时间维度: 可以将 3 个月之前的数据定义为冷数据，最近 3 个月的数据定义为热数据
   - 也可以是状态维: 比如订单的状态, 已完结的订单定义为冷数据, 未完结的订单定义为热数据
   - 也可以将时间维度和状态维度组合起来: 比如下单时间大于 3 个月且订单状态为已完结的定义为冷数据, 反则为热数据

8. 如何实现冷热数据分离

   - 业务代码修改: 在数据修改时触发冷热分离, 发现是冷数据就删除热库数据并添加到冷库 {侵入+耦合+无法按照时间进行区分}
   - 监听数据库日志: binlog 日志+canal{无法按照时间区分}
     ![avatar](/static/image/db/mysql-hl.png)
   - 定时任务扫描: 定时任务扫描{可以根据时间+状态}

9. 冷热分离的问题

   - 在冷热分离的处理逻辑中一定要保证热库/冷库中的数据一致性问题: 分布式事务{两个库}
